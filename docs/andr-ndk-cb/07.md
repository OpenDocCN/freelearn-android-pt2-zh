# 第七章。其他安卓 NDK 应用编程接口

在本章中，我们将介绍:

*   用 android ndk 中的 unigraphics 库编程
*   用安卓 NDK 的动态链接库编程
*   安卓 NDK 系统中使用 zlib 压缩库编程
*   用 NDK 安卓系统中的 OpenSL ES 音频库编程音频
*   用安卓 NDK 的 OpenMAX AL 多媒体库编程

# 简介

前面三章我们已经介绍了安卓 NDK OpenGL ES API ( [第四章](04.html "Chapter 4. Android NDK OpenGL ES API")、*安卓 NDK OpenGL ES API* 、原生应用 API ( [第五章](05.html "Chapter 5. Android Native Application API")、*安卓原生应用 API* )和多线程 API ( [第六章](06.html "Chapter 6. Android NDK Multithreading")、*安卓 NDK 多线程*)。这是最后一章关于安卓 NDK API 的说明，我们将介绍更多的库，包括`jnigraphics`库、动态链接器库、`zlib`压缩库、OpenSL ES Audio 库和 OpenMAX AL 多媒体库。

我们先介绍两个小库，`jnigraphics`和动态链接器，它们只有很少的 API 函数，使用起来很方便。然后我们描述`zlib`压缩库，可以用来压缩和解压缩`.zlib`和`.gzip`格式的数据。OpenSL ES 音频库和 OpenMAX AL 多媒体库是安卓较新版本上可用的两个相对较新的应用编程接口。这两个库中的 API 函数尚未冻结，仍在发展中。因为源代码的兼容性并不是 Android 上库开发的目标，正如 NDK OpenSL ES 和 OpenMAX AL 文档中所述，这两个库的未来版本可能需要我们更新代码。

此外，请注意，OpenSL ES 和 OpenMAX AL 是相当复杂的库，具有许多应用编程接口函数。我们只能用简单的例子介绍这两个库的基本用法。感兴趣的读者应该参考图书馆文档了解更多细节。

# 用安卓 NDK 的 jnigraphics 库编程

`jnigraphics`库为本机代码提供了一个基于 C 的接口，用于访问 Java 位图对象的像素缓冲区，该接口可作为 Android 2.2 系统映像及更高版本上的稳定本机 API。本食谱讨论如何使用`jnigraphics`库。

## 准备…

读者应该知道如何创建一个安卓 NDK 项目。详细说明可以参考[第一章](01.html "Chapter 1. Hello NDK")*你好 NDK* 的*写你好 NDK 程序*食谱。

## 怎么做...

以下步骤描述了如何创建一个简单的安卓 应用程序，演示`jnigraphics`库的用法:

1.  创建一个名为`JNIGraphics`的安卓应用。将包名设置为`cookbook.chapter7.JNIGraphics`。有关更多详细说明，请参考[第 2 章](02.html "Chapter 2. Java Native Interface")、 *Java 本机接口*的*加载本机库和注册本机方法*配方。
2.  右键点击项目 **JNIGraphics** ，选择**安卓工具** | **添加原生支持**。
3.  在`cookbook.chapter7.JNIGraphics`包中添加两个名为`MainActivity.java`和`RenderView.java`的 Java 文件。`RenderView.java`加载`JNIGraphics`原生库，调用原生`naDemoJniGraphics` 方法处理位图，最终显示位图。`MainActivity.java`文件创建位图，将其传递给 `RenderView`类，并将`RenderView`类设置为其内容视图。
4.  在`jni`文件夹下添加`mylog.h`和`JNIGraphics.cpp`文件。`mylog.h`包含安卓原生的 `logcat`实用程序功能，而`JNIGraphics.cpp`文件包含用`jnigraphics`库函数处理位图的原生代码。`JNIGraphics.cpp`文件中的部分代码如下所示:

    ```cpp
    void naDemoJniGraphics(JNIEnv* pEnv, jclass clazz, jobject pBitmap) {
      int lRet, i, j;
      AndroidBitmapInfo lInfo;
      void* lBitmap;
      //1\. retrieve information about the bitmap
      if ((lRet = AndroidBitmap_getInfo(pEnv, pBitmap, &lInfo)) < 0) {
        return;
      }
      if (lInfo.format != ANDROID_BITMAP_FORMAT_RGBA_8888) {
        return;
      }
      //2\. lock the pixel buffer and retrieve a pointer to it
      if ((lRet = AndroidBitmap_lockPixels(pEnv, pBitmap, &lBitmap)) < 0) {
        LOGE(1, "AndroidBitmap_lockPixels() failed! error = %d", lRet);
      }
      //3\. manipulate the pixel buffer
      unsigned char *pixelBuf = (unsigned char*)lBitmap;
      for (i = 0; i < lInfo.height; ++i) {
        for (j = 0; j < lInfo.width; ++j) {
        unsigned char *pixelP = pixelBuf + i*lInfo.stride + j*4;
        *pixelP = (unsigned char)0x00;	//remove R component
    //    *(pixelP+1) = (unsigned char)0x00;	//remove G component
    //    *(pixelP+2) = (unsigned char)0x00;	//remove B component
    //    LOGI(1, "%d:%d:%d:%d", *pixelP, *(pixelP+1), *(pixelP+2), *(pixelP+3));}
      }
      //4\. unlock the bitmap
      AndroidBitmap_unlockPixels(pEnv, pBitmap);
    }
    ```

5.  在`jni` 文件夹中添加一个`Android.mk`文件，内容如下:

    ```cpp
    LOCAL_PATH := $(call my-dir)
    include $(CLEAR_VARS)
    LOCAL_MODULE    := JNIGraphics
    LOCAL_SRC_FILES := JNIGraphics.cpp
    LOCAL_LDLIBS := -llog -ljnigraphics
    include $(BUILD_SHARED_LIBRARY)
    ```

6.  Build and run the Android project. We can enable code to remove different components from the bitmap. The following screenshots show the original picture and the ones with red, green, and blue component removed respectively:

    ![How to do it...](graphics/1505_07_01.jpg)

## 它是如何工作的...

在我们的示例项目中，我们通过将位图的一个 RGB 分量设置为零，修改了传递给本机`naDemoJniGraphics`函数的 。

### 注

`jnigraphics`库仅适用于安卓 API 级(安卓 2.2，Froyo)及更高版本。

使用 `jnigraphics`库应遵循以下步骤:

1.  在我们使用`jnigraphics` API 的源代码中包含`<android/bitmap.h>`头。
2.  通过在`Android.mk`文件中包含以下行链接到`jnigraphics`库。

    ```cpp
    LOCAL_LDLIBS += -ljnigraphics
    ```

3.  In the source code, call `AndroidBitmap_getInfo` to retrieve the information about a bitmap object. The `AndroidBitmap_getInfo` function has the following prototype:

    ```cpp
    int AndroidBitmap_getInfo(JNIEnv* env, jobject jbitmap, AndroidBitmapInfo* info);
    ```

    该函数接受指向`JNIEnv`结构的指针、位图对象的引用和指向`AndroidBitmapInfo`结构的指针。如果呼叫成功，将填充`info`指向的数据结构。

    `AndroidBitmapInfo`定义如下:

    ```cpp
    typedef struct {
    uint32_t    width;
    	uint32_t    height;
    uint32_t    stride;
    int32_t     format;
    uint32_t    flags; 
    } AndroidBitmapInfo;
    ```

    `width`和`height`表示位图的像素宽度和高度。`stride`指在像素缓冲区的行之间跳过的字节数。该数字必须不小于宽度(以字节为单位)。大多数情况下，`stride`和`width`是一样的。然而，有时像素缓冲区包含填充，因此步幅可以大于位图`width`。

    `format`是颜色格式，可以是`ANDROID_BITMAP_FORMAT_RGBA_8888`、`ANDROID_BITMAP_FORMAT_RGB_565`、`ANDROID_BITMAP_FORMAT_RGBA_4444`、`ANDROID_BITMAP_FORMAT_A_8`或`bitmap.h`头文件中定义的`ANDROID_BITMAP_FORMAT_NONE`。

    在我们的例子中，我们使用`ANDROID_BITMAP_FORMAT_RGBA_8888`作为位图格式。因此，每个像素占用 4 个字节。

4.  Lock the pixel address by calling the `AndroidBitmap_lockPixels` function:

    ```cpp
    int AndroidBitmap_lockPixels(JNIEnv* env, jobject jbitmap, void** addrPtr);
    ```

    如果调用成功，`*addrPtr`指针将指向位图的像素。一旦像素地址被锁定，像素的存储器将不会移动，直到像素地址被解锁。

5.  在本机代码中操作像素缓冲区。
6.  Unlock the pixel address by calling `AndroidBitmap_unlockPixels`:

    ```cpp
    int AndroidBitmap_unlockPixels(JNIEnv* env, jobject jbitmap);
    ```

    请注意，如果`AndroidBitmap_lockPixels`函数成功，则必须调用该函数。

    ### 注

    成功后， `jnigraphics`函数返回`ANDROID_BITMAP_RESUT_SUCCESS`，其值为`0`。失败时，它们返回负值。

## 还有更多…

回想一下，我们使用[第 4 章](04.html "Chapter 4. Android NDK OpenGL ES API")*安卓 NDK OpenGL ES API* 中的`jnigraphics`库在*贴图纹理到 3D 对象中加载纹理。我们可以重新查看食谱，了解如何使用`jnigraphics`库的另一个例子。*

# 用安卓 NDK 的动态链接器库编程

动态加载是一种在运行时将库加载到 内存中，并执行库内定义的函数或访问库内定义的变量的技术。它允许应用程序在没有这些库的情况下启动。

我们在这本书的几乎每一个食谱中都看到了动态加载。当我们调用`System.loadLibrary`或`System.load`函数加载本机库时，我们使用的是动态加载。

自 Android 1.5 以来，Android NDK 提供了动态链接器库来支持 NDK 的动态加载。这个配方讨论了动态链接器库函数。

## 做好准备...

读者应该知道如何创建一个安卓 NDK 项目。详细说明可以参考[第一章](01.html "Chapter 1. Hello NDK")*你好 NDK* 的*写你好 NDK 程序*食谱。

## 怎么做...

下面的步骤描述了如何使用动态链接库创建一个安卓应用程序来加载数学库并计算 2 的平方根。

1.  创建一个名为`DynamicLinker`的安卓应用。将包名设置为`cookbook.chapter7.dynamiclinker`。有关更多详细说明，请参考[第 2 章](02.html "Chapter 2. Java Native Interface")、 *Java 本机接口*的*加载本机库和注册本机方法*配方。
2.  右键点击`DynamicLinker`项目，选择**安卓工具** | **添加原生支持**。
3.  在`cookbook.chapter7.dynamiclinker`包下添加一个名为`MainActivity.java`的 Java 文件。这个 Java 文件只是加载原生的`DynamicLinker`库并调用原生的`naDLDemo`方法。
4.  Add the `mylog.h` and `DynamicLinker.cpp` files under the `jni` folder. A part of the code in the `OpenSLESDemo.cpp` file is shown in the following code.

    `naDLDemo`加载`libm.so`库， 获取`sqrt`函数的地址，用输入参数`2.0`调用该函数:

    ```cpp
    void naDLDemo(JNIEnv* pEnv, jclass clazz) {
      void *handle;
      double (*sqrt)(double);
      const char *error;
      handle = dlopen("libm.so", RTLD_LAZY);
      if (!handle) {
        LOGI(1, "%s\n", dlerror());
        return;
      }
      dlerror();    /* Clear any existing error */
      *(void **) (&sqrt) = dlsym(handle, "sqrt");
      if ((error = dlerror()) != NULL)  {
        LOGI(1, "%s\n", error);
        return;
      }
      LOGI(1, "%f\n", (*sqrt)(2.0));
    }
    ```

5.  在`jni`文件夹下添加一个`Android.mk`文件，内容如下:

    ```cpp
    LOCAL_PATH := $(call my-dir)
    include $(CLEAR_VARS)
    LOCAL_MODULE    := DynamicLinker
    LOCAL_SRC_FILES := DynamicLinker.cpp
    LOCAL_LDLIBS := -llog -ldl
    include $(BUILD_SHARED_LIBRARY)
    ```

6.  Build and run the Android project, and use the following command to monitor the `logcat` output:

    ```cpp
    $ adb logcat -v time DynamicLinker:I *:S
    ```

    `logcat`输出截图如下:

    ![How to do it...](graphics/1505_07_05.jpg)

## 它是如何工作的...

为了用动态加载库`libdl.so`构建，我们必须在`Android.mk`文件中添加以下行:

```cpp
LOCAL_LDLIBS := -ldl
```

安卓动态链接库 在`dlfcn.h`头文件中定义了以下功能:

```cpp
void*        dlopen(const char*  filename, int flag);
int          dlclose(void*  handle);
const char*  dlerror(void);
void*        dlsym(void*  handle, const char*  symbol);
int          dladdr(const void* addr, Dl_info *info);
```

`dlopen`函数动态加载库。第一个参数表示库名，第二个参数表示加载模式，描述`dlopen`如何解析未定义的符号。当加载一个对象文件(例如，共享库、可执行文件等)时，它可能包含对其地址未知的符号的引用，直到加载另一个对象文件(这种符号被称为未定义符号)。在使用这些引用访问符号之前，需要对其进行解析。以下两种模式决定何时进行解析:

*   `RTLD_NOW`:加载对象文件时，未定义的符号被解析。这意味着解析发生在`dlopen`函数返回之前。如果执行了解析但从未访问过引用，这可能是一种浪费。
*   `RTLD_LAZY`:可以在 `dlopen`函数返回后进行解析，即在执行代码时解析未定义的符号。

以下两种模式决定了加载对象中符号的可见性。它们可以用前面提到的两种模式进行“或”运算:

*   `RTLD_LOCAL`:符号对于另一个对象将不可用
*   `RTLD_GLOBAL`:符号可用于随后加载的对象

`dlopen`功能成功后返回手柄。该手柄应用于接下来对`dlsym`和`dlclose`的呼叫。

`dlclose`函数只是减少加载的库句柄的引用计数。如果引用计数减少到零，库将被卸载。

`dlerror`函数返回一个字符串，描述自上次调用`dlerror`以来调用`dlopen`、`dlsym`或`dlclose`时发生的最新错误。如果没有出现这样的错误，则返回`NULL`。

`dlsym`函数返回由输入参数句柄引用的已加载动态库的给定符号的内存地址。返回的地址可用于访问符号。

`dladdr`函数获取一个地址，并试图通过`DI_info`类型的`info`参数 返回关于该地址和库的更多信息。 `DI_info`数据结构定义如下代码片段所示:

```cpp
typedef struct {
   const char *dli_fname;  
   void       *dli_fbase;  
   const char *dli_sname;  
   void       *dli_saddr;  
} Dl_info;
```

`dli_fname`表示输入参数`addr`引用的共享对象的路径。`dli_fbase`是加载共享对象的地址。`dli_sname`表示地址低于`addr`的最近符号的名称，`dli_saddr`是`dli_sname`命名的符号的地址。

在我们的例子中，我们演示了前四个 函数的用法。我们通过`dlopen`加载数学库，通过`dlsym`获取`sqrt`函数的地址，通过`dlerror`检查错误，通过`dlclose`关闭库。

有关动态加载库的更多详细信息，请参考和 http://linux.die.net/man/3/dlopen。

# 用安卓 NDK 的 zlib 压缩库编程

`zlib`是一个广泛使用的无损数据压缩库， 适用于 Android 1.5 系统镜像或更高版本。本食谱讨论了`zlib`功能的基本用法。

## 做好准备...

读者应该知道如何创建一个安卓 NDK 项目。详细说明可以参考[第一章](01.html "Chapter 1. Hello NDK")*你好 NDK* 的*写你好 NDK 程序*食谱。

## 怎么做...

以下步骤描述了如何创建一个简单的安卓应用程序来演示`zlib`库的用法:

1.  创建一个名为`ZlibDemo`的安卓应用。将包名设置为`cookbook.chapter7.zlibdemo`。有关更多详细说明，请参考[第 2 章](02.html "Chapter 2. Java Native Interface")、 *Java 本机接口*的*加载本机库和注册本机方法*配方。
2.  右键点击项目 **ZlibDemo** ，选择**安卓工具** | **添加原生支持**。
3.  在`cookbook.chapter7.zlibdemo`包中添加一个名为`MainActivity.java`的 Java 文件。`MainActivity.java`文件加载`ZlibDemo`本机库，并调用本机方法。
4.  Add `mylog.h`, `ZlibDemo.cpp`, and `GzFileDemo.cpp` files under the `jni` folder. The `mylog.h` header file contains the Android native `logcat` utility functions, while `ZlibDemo.cpp` and `GzFileDemo.cpp` files contain code for compression and decompression. A part of the code in `ZlibDemo.cpp` and `GzFileDemo.cpp` is shown in the following code.

    `ZlibDemo.cpp`包含压缩和解压缩内存中数据的本机代码。

    `compressUtil`压缩并解压内存中的数据。

    ```cpp
    void compressUtil(unsigned long originalDataLen) {
      int rv;
      int compressBufBound = compressBound(originalDataLen);
      compressedBuf = (unsigned char*) malloc(sizeof(unsigned char)*compressBufBound);
      unsigned long compressedDataLen = compressBufBound;
      rv = compress2(compressedBuf, &compressedDataLen, dataBuf, originalDataLen, 6);
      if (Z_OK != rv) {
        LOGE(1, "compression error");
        free(compressedBuf);
        return;
      }
      unsigned long decompressedDataLen = S_BUF_SIZE;
      rv = uncompress(decompressedBuf, &decompressedDataLen, compressedBuf, compressedDataLen);
      if (Z_OK != rv) {
        LOGE(1, "decompression error");
        free(compressedBuf);
        return;
      }
      if (0 == memcmp(dataBuf, decompressedBuf, originalDataLen)) {
        LOGI(1, "decompressed data same as original data");
      }   //free resource
      free(compressedBuf);
    }
    ```

5.  `naCompressAndDecompress` generates data for compression and calls the `compressUtil` function to compress and decompress the generated data:

    ```cpp
    void naCompressAndDecompress(JNIEnv* pEnv, jclass clazz) {
      unsigned long originalDataLen = getOriginalDataLen();
      LOGI(1, "---------data with repeated bytes---------")
      generateOriginalData(originalDataLen);
      compressUtil(originalDataLen);
      LOGI(1, "---------data with random bytes---------")
      generateOriginalDataRandom(originalDataLen);
      compressUtil(originalDataLen);
    }
    ```

    `GzFileDemo.cpp`包含压缩和解压缩文件中数据的本机代码。

    `writeToFile`将字符串写入`gzip`文件。写入时应用压缩:

    ```cpp
    int writeToFile() {
      gzFile file;
      file = gzopen("/sdcard/test.gz", "w6");
      if (NULL == file) {
        LOGE(1, "cannot open file to write");
        return 0;
      }
      const char* dataStr = "hello, Android NDK!";
      int bytesWritten = gzwrite(file, dataStr, strlen(dataStr));
      gzclose(file);
      return bytesWritten;
    }
    ```

    `readFromFile`从`gzip`文件读取数据。 解压应用于阅读:

    ```cpp
    void readFromFile(int pBytesToRead) {
      gzFile file;
      file = gzopen("/sdcard/test.gz", "r6");
      if (NULL == file) {
        LOGE(1, "cannot open file to read");
        return;
      }
      char readStr[100];
      int bytesRead = gzread(file, readStr, pBytesToRead);
      gzclose(file);
      LOGI(1, "%d: %s", bytesRead, readStr);
    }
    ```

6.  在`jni`文件夹下添加一个`Android.mk`文件，内容如下:

    ```cpp
    LOCAL_PATH := $(call my-dir)
    include $(CLEAR_VARS)
    LOCAL_MODULE    := ZlibDemo
    LOCAL_SRC_FILES := ZlibDemo.cpp GzFileDemo.cpp
    LOCAL_LDLIBS := -llog -lz
    include $(BUILD_SHARED_LIBRARY)
    ```

7.  Enable the `naCompressAndDecompress` function and disable the `naGzFileDemo` function, build and run the application. We can monitor the `logcat` output with the following command:

    ```cpp
    $ adb logcat -v time ZlibDemo:I *:S
    ```

    `logcat`输出截图如下:

    ![How to do it...](graphics/1505_07_06.jpg)

    启用`naGzFileDemo`功能，禁用`naCompressAndDecompress` 功能，构建并运行应用程序。`logcat`输出如下图所示:

    ![How to do it...](graphics/1505_07_07.jpg)

## 它是如何工作的...

`zlib`库为内存中的数据和文件提供压缩和解压缩功能。我们演示了两个用例。在 `ZlibDemo.cpp`文件中，我们创建了两个数据缓冲区，一个是重复字节，另一个是随机字节。我们通过以下步骤压缩和解压缩数据:

1.  Compute the upper bound on the compressed size. This is done by the following function:

    ```cpp
    uLong compressBound(uLong sourceLen);
    ```

    在对源数据的`sourceLen`字节调用`compress`或`compress2`函数后，该函数返回压缩数据的最大大小。

2.  分配存储压缩数据的内存。
3.  Compress the data. This is done by the following function:

    ```cpp
    int compress2(Bytef *dest,   uLongf *destLen, const Bytef *source, uLong sourceLen, int level);
    ```

    这个函数接受五个输入参数。`source`和`sourceLen`指的是源数据缓冲区和源数据长度。`dest`和`destLen`表示用于存储压缩数据的数据缓冲区和该缓冲区的大小。 `destLen`的值必须至少是调用函数时`compressBound`返回的值。当功能返回时，`destLen`被设置为压缩数据的实际大小。最后一个输入参数`level`可以是 0 到 9 之间的值，其中 1 表示最佳速度，9 表示最佳压缩。在我们的示例中，我们将 的值设置为 6，以在速度和压缩之间进行折衷。

    ### 注

    我们也可以使用压缩函数来压缩数据，它没有级别输入参数。相反，它采用默认级别，相当于 6。

4.  Decompress the data. This is done by using the `uncompress` function:

    ```cpp
    int uncompress(Bytef *dest,   uLongf *destLen, const Bytef *source, uLong sourceLen);
    ```

    输入参数的含义与`compress2`函数相同。

5.  Compare the decompressed data with the original data. This is just a simple check.

    默认情况下，这些函数对压缩数据使用`zlib`格式。

    该库还支持`gzip`格式的文件读写。这一点在`GzFileDemo.cpp`中有所展示。这些功能的用法类似于文件读写的 `stdio`功能。

我们将压缩数据写入`gzip`文件，然后从中读取未压缩数据的步骤如下所示:

1.  Open a `gzip` file for writing. This is done by the following function:

    ```cpp
    gzFile gzopen(const char *path, const char *mode);
    ```

    该函数接受文件名和打开模式，并在成功时返回一个`gzFile`对象。 模式类似于`fopen`功能，但具有可选的压缩级别。在我们的例子中，我们用`w6`调用`gzopen`来指定压缩级别为 6。

2.  Write data to a `gzip` file. This is done by the following function:

    ```cpp
    int gzwrite(gzFile file, voidpc buf, unsigned len);
    ```

    该函数将未压缩的数据写入压缩文件。输入参数`file`指的是压缩文件，`buf`指的是未压缩的数据缓冲区，`len`表示要写入的字节数。该函数返回实际写入的未压缩数据的数量。

3.  Close the `gzip` file. This is done by the following function:

    ```cpp
    int ZEXPORT    gzclose(gzFile file);
    ```

    调用此函数将刷新所有挂起的输出并关闭压缩文件。

4.  打开文件阅读。我们将`r6`传递给了功能。
5.  Read data from the compressed file. This is done by the `gzread` function.

    ```cpp
    int gzread(gzFile file, voidp buf, unsigned len);
    ```

    该功能将文件中的`len`字节数读入`buf`。它返回读取的实际字节数。

    ### 注

    `zlib`库支持两种压缩格式，`zlib`和`gzip`。`zlib`设计紧凑快速，所以最好用在内存和通讯通道上。另一方面，`gzip`是为文件系统上的单个文件压缩而设计的，文件系统有一个更大的头来维护目录信息，并且使用比`zlib`更慢的检查方法。

为了使用`zlib`库，我们必须在源代码中包含`zlib.h`头文件，并在`Android.mk`中添加以下行来链接到`libz.so`库:

```cpp
LOCAL_LDLIBS := -lz
```

## 还有更多...

回想一下[第五章](05.html "Chapter 5. Android Native Application API")、*安卓原生应用 AP* 中*在安卓 NDK* 管理资产的食谱，我们编制了 `libpng`库，需要`zlib`库。

我们只介绍了`zlib`库提供的一些功能。 更多信息可以参考`platforms/android-<version>/arch-arm/usr/include/`文件夹中的`zlib.h`和`zconf.h`头文件。 `zlib`图书馆的详细文档可以在[http://www.zlib.net/manual.html](http://www.zlib.net/manual.html)找到。

# 用安卓 NDK 的 OpenSL ES 音频库编程音频

OpenSL ES 是一个 c 语言的应用层音频库，Android NDK 原生音频 API 基于 OpenSL ES 1.0.1 标准，带有 Android 专用扩展。该 API 适用于 Android 2.3 或更高版本，某些功能仅在 Android 4.0 或更高版本上受支持。该库中的 API 函数尚未冻结，仍在发展中。这个库的未来版本可能需要我们更新代码。这个食谱介绍了安卓环境下的 OpenSL ES APIs。

## 做好准备...

在我们开始用 OpenSL ES 编码之前，了解一些库的基础知识是非常重要的。 OpenSL ES 代表嵌入式系统的**开放声音库**，是一个跨平台、免版税的 C 语言应用级 API，供开发者访问嵌入式系统的音频功能。该库规范定义了音频回放和录制、音频效果和控制、2D 和 3D 音频、高级 MIDI 等功能。基于支持的功能，OpenSL ES 定义了三个配置文件，包括电话、音乐和游戏。

但是，安卓本地音频应用编程接口不符合这三个配置文件中的任何一个，因为它没有实现任何配置文件中的所有功能。此外，安卓实现了一些安卓特有的功能，比如安卓缓冲队列。关于安卓系统支持什么的详细描述，我们可以参考`docs/opensles/`文件夹下的安卓 NDK 系统的 OpenSL ES 文档。

虽然 OpenSL ES API 是用 C 实现的，但它采用了面向对象的方法，基于对象和接口构建库:

*   **对象**:对象是一组资源及其状态的抽象。每个对象在创建时都有一个指定的类型，该类型决定了对象可以执行的任务集。它类似于 C++中的类概念。
*   **接口**:接口是一个对象可以提供的一组特征的抽象。这些特性作为一组方法展示给我们，每个接口的类型决定了所展示的特性的确切集合。在代码中，接口的类型由接口标识来标识。

需要注意的是，对象在代码中没有实际的表示形式。我们改变对象的状态，并通过接口访问它的特性。一个对象可以有一个或多个接口实例。但是，单个对象的两个实例不能是同一类型。另外，一个给定的接口实例可以 只属于一个对象。如下图所示，可以说明这种关系:

![Getting ready...](graphics/1505_07_11.jpg)

如图所示，对象 1 和对象 2 具有不同的类型，因此公开了不同的接口。对象 1 有三个接口实例，都有不同的类型。而对象 2 有另外两个不同类型的接口实例。请注意，对象 1 的接口 2 和对象 2 的接口 4 具有相同的类型，这意味着对象 1 和对象 2 都支持通过接口类型 b 的接口公开的功能

## 怎么做...

以下步骤描述了如何使用本机音频库创建一个简单的安卓应用程序来录制和播放音频:

1.  创建一个名为`OpenSLESDemo`的安卓应用。将包名设置为`cookbook.chapter7.opensles`。有关更多详细说明，请参考[第 2 章](02.html "Chapter 2. Java Native Interface")、 *Java 本机接口*的*加载本机库和注册本机方法*配方。
2.  右键点击项目**打开工具**，选择**安卓工具** | **添加原生支持**。
3.  在`cookbook.chapter7.opensles`包中添加一个名为`MainActivity.java`的 Java 文件。这个 Java 文件只是加载本机库`OpenSLESDemo`并调用本机方法来录制和播放音频。
4.  Add `mylog.h`, `common.h`, `play.c`, `record.c`, and `OpenSLESDemo.cpp` files in the `jni` folder. A part of the code in the `play.c`, `record.c`, and `OpenSLESDemo.cpp` files is shown in the following code snippet.

    `record.c`包含创建一个 录音机对象并记录音频的代码。

    `createAudioRecorder`创建并实现一个音频播放器对象，获取记录和缓冲队列接口:

    ```cpp
    jboolean createAudioRecorder() {
       SLresult result;
       SLDataLocator_IODevice loc_dev = {SL_DATALOCATOR_IODEVICE, SL_IODEVICE_AUDIOINPUT, SL_DEFAULTDEVICEID_AUDIOINPUT, NULL};
       SLDataSource audioSrc = {&loc_dev, NULL};
       SLDataLocator_AndroidSimpleBufferQueue loc_bq = {SL_DATALOCATOR_ANDROIDSIMPLEBUFFERQUEUE, 1};
       SLDataFormat_PCM format_pcm = {SL_DATAFORMAT_PCM, 1, SL_SAMPLINGRATE_16,
           SL_PCMSAMPLEFORMAT_FIXED_16, SL_PCMSAMPLEFORMAT_FIXED_16,
           SL_SPEAKER_FRONT_CENTER, SL_BYTEORDER_LITTLEENDIAN};
       SLDataSink audioSnk = {&loc_bq, &format_pcm};
       const SLInterfaceID id[1] = {SL_IID_ANDROIDSIMPLEBUFFERQUEUE};
       const SLboolean req[1] = {SL_BOOLEAN_TRUE};
       result = (*engineEngine)->CreateAudioRecorder(engineEngine, &recorderObject, &audioSrc,
               &audioSnk, 1, id, req);
         result = (*recorderObject)->Realize(recorderObject, SL_BOOLEAN_FALSE);
       result = (*recorderObject)->GetInterface(recorderObject, SL_IID_RECORD, &recorderRecord);
       result = (*recorderObject)->GetInterface(recorderObject, SL_IID_ANDROIDSIMPLEBUFFERQUEUE, &recorderBufferQueue);
       result = (*recorderBufferQueue)->RegisterCallback(recorderBufferQueue, bqRecorderCallback, NULL);
       return JNI_TRUE;
    }
    ```

    `startRecording`将缓冲区排队到 存储录音音频，并将音频对象状态设置为录音:

    ```cpp
    void startRecording() {
       SLresult result;
       recordF = fopen("/sdcard/test.pcm", "wb");
       result = (*recorderRecord)->SetRecordState(recorderRecord, SL_RECORDSTATE_STOPPED);
       result = (*recorderBufferQueue)->Clear(recorderBufferQueue);
       recordCnt = 0;
       result = (*recorderBufferQueue)->Enqueue(recorderBufferQueue, recorderBuffer,
               RECORDER_FRAMES * sizeof(short));
       result = (*recorderRecord)->SetRecordState(recorderRecord, SL_RECORDSTATE_RECORDING);
    }
    ```

    每次缓冲队列准备接受新的数据块时，都会调用`bqRecorderCallback`回调方法。当缓冲区充满音频数据时，就会出现这种情况:

    ```cpp
    void bqRecorderCallback(SLAndroidSimpleBufferQueueItf bq, void *context) {
       int numOfRecords = fwrite(recorderBuffer, sizeof(short), RECORDER_FRAMES, recordF);
       fflush(recordF);
       recordCnt++;
       SLresult result;
       if (recordCnt*5 < RECORD_TIME) {
        result = (*recorderBufferQueue)->Enqueue(recorderBufferQueue, recorderBuffer,
            RECORDER_FRAMES * sizeof(short));
       } else {
        result = (*recorderRecord)->SetRecordState(recorderRecord, SL_RECORDSTATE_STOPPED);
        if (SL_RESULT_SUCCESS == result) {
          fclose(recordF);
        }
       }
    }
    ```

    `play.c`包含创建音频播放器对象并播放音频的代码。

    `createBufferQueueAudioPlayer`创建并 实现一个播放来自缓冲队列的音频的音频播放器对象:

    ```cpp
    void createBufferQueueAudioPlayer() {
       SLresult result;
       SLDataLocator_AndroidSimpleBufferQueue loc_bufq = {SL_DATALOCATOR_ANDROIDSIMPLEBUFFERQUEUE, 1};
       SLDataFormat_PCM format_pcm = {SL_DATAFORMAT_PCM, 1, SL_SAMPLINGRATE_16,
           SL_PCMSAMPLEFORMAT_FIXED_16, SL_PCMSAMPLEFORMAT_FIXED_16,
           SL_SPEAKER_FRONT_CENTER, SL_BYTEORDER_LITTLEENDIAN};
       SLDataSource audioSrc = {&loc_bufq, &format_pcm};
       SLDataLocator_OutputMix loc_outmix = {SL_DATALOCATOR_OUTPUTMIX, outputMixObject};
       SLDataSink audioSnk = {&loc_outmix, NULL};
       const SLInterfaceID ids[3] = {SL_IID_BUFFERQUEUE, SL_IID_EFFECTSEND, SL_IID_VOLUME};
       const SLboolean req[3] = {SL_BOOLEAN_TRUE, SL_BOOLEAN_TRUE, SL_BOOLEAN_TRUE};
       result = (*engineEngine)->CreateAudioPlayer(engineEngine, &bqPlayerObject, &audioSrc, &audioSnk, 3, ids, req);
       result = (*bqPlayerObject)->Realize(bqPlayerObject, SL_BOOLEAN_FALSE);
       result = (*bqPlayerObject)->GetInterface(bqPlayerObject, SL_IID_PLAY, &bqPlayerPlay);
       result = (*bqPlayerObject)->GetInterface(bqPlayerObject, SL_IID_BUFFERQUEUE,
               &bqPlayerBufferQueue);
       result = (*bqPlayerBufferQueue)->RegisterCallback(bqPlayerBufferQueue, bqPlayerCallback, NULL);
       result = (*bqPlayerObject)->GetInterface(bqPlayerObject, SL_IID_EFFECTSEND,
               &bqPlayerEffectSend);
       result = (*bqPlayerObject)->GetInterface(bqPlayerObject, SL_IID_VOLUME, &bqPlayerVolume);
    }
    ```

    `startPlaying`用`test.cpm`文件中的数据 填充缓冲区并开始播放:

    ```cpp
    jboolean startPlaying() {
      SLresult result;
      recordF = fopen("/sdcard/test.pcm", "rb");
      noMoreData = 0;
      int numOfRecords = fread(recorderBuffer, sizeof(short), RECORDER_FRAMES, recordF);
      if (RECORDER_FRAMES != numOfRecords) {
        if (numOfRecords <= 0) {
          return JNI_TRUE;
        }
        noMoreData = 1;
      }   
    result = (*bqPlayerBufferQueue)->Enqueue(bqPlayerBufferQueue, recorderBuffer, RECORDER_FRAMES * sizeof(short));
      result = (*bqPlayerPlay)->SetPlayState(bqPlayerPlay, SL_PLAYSTATE_PLAYING);
      return JNI_TRUE;
    }
    ```

    `bqPlayerCallback`每当缓冲队列准备接受新的缓冲时，调用这个回调方法。当缓冲区播放完毕时会发生这种情况:

    ```cpp
    void bqPlayerCallback(SLAndroidSimpleBufferQueueItf bq, void *context) {
       if (!noMoreData) {
            SLresult result;
    int numOfRecords = fread(recorderBuffer, sizeof(short), RECORDER_FRAMES, recordF);
      if (RECORDER_FRAMES != numOfRecords) {
        if (numOfRecords <= 0) {
          noMoreData = 1;
          (*bqPlayerPlay)->SetPlayState(bqPlayerPlay, SL_PLAYSTATE_STOPPED);
          fclose(recordF);
          return;
        }
        noMoreData = 1;
      } 
      result = (*bqPlayerBufferQueue)->Enqueue(bqPlayerBufferQueue, recorderBuffer,  RECORDER_FRAMES * sizeof(short));
       } else {
         (*bqPlayerPlay)->SetPlayState(bqPlayerPlay, SL_PLAYSTATE_STOPPED);
         fclose(recordF);
       }
    }
    ```

    `OpenSLESDemo.cpp`包含创建 OpenSL ES 引擎对象的代码，释放对象，并注册 原生方法:

    `naCreateEngine`创建引擎对象并输出混合对象。

    ```cpp
    void naCreateEngine(JNIEnv* env, jclass clazz) {
       SLresult result;
       result = slCreateEngine(&engineObject, 0, NULL, 0, NULL, NULL);
       result = (*engineObject)->Realize(engineObject, SL_BOOLEAN_FALSE);
       result = (*engineObject)->GetInterface(engineObject, SL_IID_ENGINE, &engineEngine);
       const SLInterfaceID ids[1] = {SL_IID_ENVIRONMENTALREVERB};
       const SLboolean req[1] = {SL_BOOLEAN_FALSE};
       result = (*engineEngine)->CreateOutputMix(engineEngine, &outputMixObject, 1, ids, req);
       result = (*outputMixObject)->Realize(outputMixObject, SL_BOOLEAN_FALSE);
       result = (*outputMixObject)->GetInterface(outputMixObject, SL_IID_ENVIRONMENTALREVERB,
               &outputMixEnvironmentalReverb);
       if (SL_RESULT_SUCCESS == result) {
            result = (*outputMixEnvironmentalReverb)->SetEnvironmentalReverbProperties(
                   outputMixEnvironmentalReverb, &reverbSettings);
       }
    }
    ```

5.  向`AndroidManifest.xml`文件添加以下权限。

    ```cpp
    <uses-permission android:name="android.permission.RECORD_AUDIO"/>
    <uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE"/>
    <uses-permission android:name="android.permission.MODIFY_AUDIO_SETTINGS"></uses-permission>
    ```

6.  在`jni`文件夹 中添加一个`Android.mk`文件，内容如下:

    ```cpp
    LOCAL_PATH := $(call my-dir)
    include $(CLEAR_VARS)
    LOCAL_MODULE    := OpenSLESDemo
    LOCAL_SRC_FILES := OpenSLESDemo.cpp record.c play.c
    LOCAL_LDLIBS := -llog
    LOCAL_LDLIBS    += -lOpenSLES
    include $(BUILD_SHARED_LIBRARY)
    ```

7.  构建并运行安卓项目，使用以下命令监控`logcat`输出:

    ```cpp
    $ adb logcat -v time OpenSLESDemo:I *:S
    ```

8.  The application GUI is shown in the following screenshot:

    ![How to do it...](graphics/1505_07_08.jpg)

    *   We can start the audio recording by clicking on the **Record** button. The recording will last for 15 seconds. The `logcat` output will be as shown in the following screenshot:

        ![How to do it...](graphics/1505_07_09.jpg)

    *   一旦录制完成。安卓设备上会创建一个`/sdcard/test.pcm`文件。我们可以点击**播放**按钮播放音频文件。`logcat`输出如下截图所示:

    ![How to do it...](graphics/1505_07_10.jpg)

## 它是如何工作的...

这个示例项目演示了如何使用 OpenSL ES 音频库。我们将首先解释一些关键概念，然后描述我们如何使用 这个录音和回放 API。

### 对象创建

对象在代码中没有实际的表示，对象的创建是通过接口完成的。每一个创建一个对象的方法都会返回一个`SLObjectInf`接口，可以用来对该对象进行基本操作，也可以访问该对象的其他接口。创建对象的步骤描述如下:

1.  创建引擎对象。引擎对象是 OpenSL ES API 的入口点。创建引擎对象是通过全局函数`slCreateEngine()`完成的，该函数返回一个 `SLObjectItf`界面。
2.  实现引擎对象。一个对象只有实现了才能使用。我们将在下一节详细讨论这一点。
3.  通过`SLObjectItf`界面的`GetInterface()` 方法获取引擎对象的`SLEngineItf` 界面。
4.  调用`SLEngineItf`界面提供的对象创建方法。成功后返回新创建对象的`SLObjectItf`界面。
5.  实现新创建的对象。
6.  通过对象的`SLObjectItf`界面操作创建的对象或访问其他界面。
7.  处理完对象后，调用`SLObjectItf`接口的`Destroy()`方法释放对象及其资源。

在我们的示例项目中，我们创建并实现了引擎对象，并在`OpenSLESDemo.cpp`的`naCreateEngine`功能中获得了`SLEngineItf`界面。然后我们调用`SLEngineItf`界面展示的`CreateAudioRecorder()` 方法，在`record.c`的`createAudioRecorder`功能创建一个录音机对象。在同一功能中，我们还实现了录音机对象，并通过对象创建时返回的`SLObjectItf`接口访问了该对象的其他几个接口。完成记录器对象后，我们调用 `Destroy()`方法释放对象及其资源，如`OpenSLESDemo.cpp`的`naShutdown` 功能所示。

在创建对象时，还有一件事需要注意，那就是接口请求。一个对象创建方法通常接受三个与接口相关的参数，如下面的代码片段所示的`SLEngineItf`接口的`CreateAudioPlayer`方法所示:

```cpp
SLresult (*CreateAudioPlayer) (
SLEngineItf self,
SLObjectItf * pPlayer,
SLDataSource *pAudioSrc,
SLDataSink *pAudioSnk,
SLuint32 numInterfaces,
const SLInterfaceID * pInterfaceIds,
const SLboolean * pInterfaceRequired
);
```

最后三个输入参数与接口相关。`numInterfaces`参数表示我们请求访问的接口数量。`pInterfaceIds`是`numInterfaces`接口标识的数组，表示对象应该支持的接口类型。`pInterfaceRequired`是`SLboolean`的数组，指定请求的接口是可选的还是必需的。在我们的音频播放器示例中，我们调用了 `CreateAudioPlayer`方法来请求三种类型的接口(`SLAndroidSimpleBufferQueueItf`、`SLEffectSendItf`、`SLVolumeItf`分别由`SL_IID_BUFFERQUEUE`、`SL_IID_EFFECTSEND`和`SL_IID_VOLUME`表示)。由于`req`数组的所有元素都是`true`，所以需要所有的接口。如果对象不能提供任何接口，对象创建将失败:

```cpp
const SLInterfaceID ids[3] = {SL_IID_BUFFERQUEUE, SL_IID_EFFECTSEND, SL_IID_VOLUME};
const SLboolean req[3] = {SL_BOOLEAN_TRUE, SL_BOOLEAN_TRUE,  SL_BOOLEAN_TRUE};
result = (*engineEngine)->CreateAudioPlayer(engineEngine, &bqPlayerObject, &audioSrc, &audioSnk, 3, ids, req);
```

请注意，对象可以有隐式和显式接口。隐式接口可用于该类型的每个对象。例如， `SLObjectItf`接口是所有类型的所有对象的隐式接口。没有必要在对象创建方法中请求隐式接口。然而，如果我们想要访问一些显式接口，我们必须在方法中请求它们。

有关接口的更多信息，请参考 *OpenSL ES 1.0.1 规范*文件中的*第 3.1.6 节*、*对象和接口之间的关系*。

### 改变物体的状态

对象创建方法创建一个对象，并将其置于未实现状态。在这种状态下，对象的资源尚未分配，因此不可用。

我们需要调用对象的`SLObjectItf`接口的 `Realize()`方法，使对象过渡到已实现状态，此时资源被分配，接口可以被访问。

一旦处理完对象，我们就调用 `Destroy()`方法来释放对象及其资源。这个调用通过未实现的阶段在内部传递对象，在这个阶段释放资源。因此，首先释放资源，然后释放对象本身。

在这个配方中，我们用我们的示例项目来说明记录和回放 API。

### 使用并构建 OpenSL ES 音频库

为了调用 API 函数，我们必须在代码中添加以下几行 :

```cpp
#include <SLES/OpenSLES.h>
```

如果我们也使用安卓特有的功能，我们应该包括另一个标题:

```cpp
#include <SLES/OpenSLES_Android.h>
```

在`Android.mk`文件中，我们必须添加以下一行链接到本机 OpenSL ES 音频库:

```cpp
LOCAL_LDLIBS += libOpenSLES
```

### OpenSL ES 录音

因为安卓上的录音机没有 MIME 数据格式和`SLAudioEncoderItf`界面，所以我们只能录制 PCM 格式的音频。我们的示例演示了如何以 PCM 格式录制音频并将数据保存到文件中。这可以用下图来说明:

![OpenSL ES audio recording](graphics/1505_07_12.jpg)

在`record.c`的`createAudioRecorder` 功能中，我们创建并实现了一个录音机对象。我们将音频输入设置为数据源，将安卓缓冲队列设置为数据接收器。注意，我们注册了 `bqRecorderCallback`函数作为缓冲队列的回调函数。每当缓冲区队列准备好新的缓冲区时，将调用`bqRecorderCallback` 功能将缓冲区数据保存到`test.cpm`文件，并再次将缓冲区排队以记录新的音频数据。在 `startRecording`功能，我们开始录音。

### 注

OpenSL ES 中的回调函数是从内部非应用程序线程执行的。线程不由达尔维克虚拟机管理，因此它们无法访问 JNI。这些线程对于 OpenSL ES 实现的完整性至关重要，因此回调函数不应该阻塞或执行任何繁重的处理任务。

如果我们需要在回调函数被触发时执行繁重的任务，我们应该为另一个线程发布一个事件来处理这些任务。

这也适用于我们将在下一个食谱中介绍的 OpenMAX AL 库。更多详细信息可从`docs/opensles/`文件夹中的 NDK OpenSL ES 文档中获得。

### OpenSL 是音频回放

安卓 OpenSL ES 库为音频播放提供了很多功能。我们可以播放编码的音频文件，包括 mp3、aac 等等。我们的例子展示了如何播放 PCM 音频。如下图所示:

![OpenSL ES audio playback](graphics/1505_07_13.jpg)

我们在`OpenSLESDemo.cpp`的`naCreateEngine`函数中创建并实现了引擎对象和输出混合对象。音频播放器对象在`play.c`的`createBufferQueueAudioPlayer`功能中创建，安卓缓冲队列作为数据源，输出混音对象作为数据接收器。`bqPlayerCallback`功能通过`SLAndroidSimpleBufferQueueItf`界面注册为回调方法。每当播放器播放完一个缓冲区，缓冲区队列就为新的数据做好准备，回调函数`bqPlayerCallback`将被调用。该方法将数据从`test.pcm`文件读入缓冲区并将其排队。

在`startPlaying`功能中，我们将初始数据读入缓冲区，并将玩家状态设置为`SL_PLAYSTATE_PLAYING`。

## 还有更多...

OpenSL ES 是一个复杂的库，有超过 500 页长的规范。当使用 OpenSL ES 开发应用程序时，该规范是一个很好的参考，并且可以在安卓 NDK 系统上使用。

安卓 NDK 还附带了一个本地音频示例，演示了更多 OpenSL ES 功能的使用。

# 用安卓 NDK 的 OpenMAX AL 多媒体库编程

OpenMAX AL 是 c 语言中的一个应用级 多媒体库，Android NDK 多媒体 API 基于 OpenMAX AL 1.0.1 标准，带有 Android 特有的扩展。该应用编程接口适用于安卓 4.0 或更高版本。我们应该注意到，该应用编程接口正在发展，安卓 NDK 团队提到，未来版本的 OpenMAX AL 应用编程接口可能需要开发人员更改他们的代码。

## 做好准备...

在我们开始使用 OpenMAX AL 库编码之前，了解该库的一些基础知识非常重要。我们将在下面的文本中简要描述这个库。

OpenMAX AL 指的是**开放媒体加速** ( **OpenMAX** )库的应用层接口。它是一个免版税、跨平台、C 语言的应用程序级 API，供开发人员创建多媒体应用程序。它的主要功能包括媒体录制、媒体播放、媒体控制(例如亮度控制)和效果。与 OpenSL ES 库相比，OpenMAX AL 提供了视频和音频两种功能，但缺少 OpenSL ES 能够提供的某些音频功能，如 3D 音频和音频效果。有些应用程序可能需要同时使用这两个库。

OpenMAX AL 定义了两个配置文件，即媒体播放和媒体播放器/录像机。安卓没有实现任何一个配置文件所需的所有功能，因此安卓中的 OpenMAX AL 库不符合任何一个配置文件。此外，安卓实现了一些安卓特有的功能。

安卓 OpenMAX AL 实现提供的主要功能是处理 MPEG-2 传输流的能力。我们可以对数据流进行解复用，对视频和音频进行解码，并将其呈现为音频输出或手机屏幕。该库允许我们在媒体数据被传递到演示之前对其进行完全控制。比如我们可以调用 OpenGL ES 函数，在渲染视频数据之前对其应用图形效果。

有关安卓支持的详细描述，我们可以参考`docs/openmaxal/`文件夹下的安卓 NDK 的 OpenMAX AL 文档。

OpenMAX AL 库的设计类似于 OpenSL ES 库。它们都采用面向对象的方法，包括对象和接口在内的基本概念是相同的。读者应该参考前面的食谱来详细解释这些概念。

## 怎么做...

以下步骤描述了如何使用 OpenMAX AL 功能创建一个简单的安卓视频播放应用程序:

1.  创建一个名为`OpenMAXSLDemo`的安卓应用。将包名设置为`cookbook.chapter7.openmaxsldemo`。有关更多详细说明，请参考[第 2 章](02.html "Chapter 2. Java Native Interface")、 *Java 本机接口*的*加载本机库和注册本机方法*配方。
2.  右键点击项目 **OpenMAXSLDemo** ，选择**安卓工具** | **添加原生支持**。
3.  在包`cookbook.chapter7.openmaxsldemo`中添加一个名为`MainActivity.java`的 Java 文件。这个 Java 文件加载原生库`OpenMAXSLDemo`，设置视图，调用原生方法播放视频。
4.  Add the `mylog.h` and `OpenMAXSLDemo.c` files in the `jni` folder. A part of the code in `OpenMAXSLDemo.c` is showed in the following code snippet.

    `naCreateEngine`创建并实现引擎对象和输出混合对象。

    ```cpp
    void naCreateEngine(JNIEnv* env, jclass clazz) {
       XAresult res;
       res = xaCreateEngine(&engineObject, 0, NULL, 0, NULL, NULL);
       res = (*engineObject)->Realize(engineObject, XA_BOOLEAN_FALSE);
       res = (*engineObject)->GetInterface(engineObject, XA_IID_ENGINE, &engineEngine);
       res = (*engineEngine)->CreateOutputMix(engineEngine, &outputMixObject, 0, NULL, NULL);
       res = (*outputMixObject)->Realize(outputMixObject, XA_BOOLEAN_FALSE);
    }
    ```

    `naCreateStreamingMediaPlayer` 用数据源和数据宿创建并实现一个媒体播放器对象。获取缓冲队列接口，将`AndroidBufferQueueCallback`函数注册为回调函数。回调函数将在缓冲区被处理后被调用:

    ```cpp
    jboolean naCreateStreamingMediaPlayer(JNIEnv* env, jclass clazz, jstring filename) {
       XAresult res;
       const char *utf8FileName = (*env)->GetStringUTFChars(env, filename, NULL);
       file = fopen(utf8FileName, "rb");
       XADataLocator_AndroidBufferQueue loc_abq = { XA_DATALOCATOR_ANDROIDBUFFERQUEUE, NB_BUFFERS };
       XADataFormat_MIME format_mime = {XA_DATAFORMAT_MIME, XA_ANDROID_MIME_MP2TS, XA_CONTAINERTYPE_MPEG_TS };
       XADataSource dataSrc = {&loc_abq, &format_mime};
       XADataLocator_OutputMix loc_outmix = { XA_DATALOCATOR_OUTPUTMIX, outputMixObject };
       XADataSink audioSnk = { &loc_outmix, NULL };
       XADataLocator_NativeDisplay loc_nd = {XA_DATALOCATOR_NATIVEDISPLAY,       
               (void*)theNativeWindow, NULL};
       XADataSink imageVideoSink = {&loc_nd, NULL};
       XAboolean required[NB_MAXAL_INTERFACES] = {XA_BOOLEAN_TRUE, XA_BOOLEAN_TRUE};
       XAInterfaceID iidArray[NB_MAXAL_INTERFACES] = {XA_IID_PLAY, XA_IID_ANDROIDBUFFERQUEUESOURCE};
       res = (*engineEngine)->CreateMediaPlayer(engineEngine, &playerObj, &dataSrc, NULL,   &audioSnk, &imageVideoSink, NULL, NULL, NB_MAXAL_INTERFACES, iidArray, required );
       (*env)->ReleaseStringUTFChars(env, filename, utf8FileName);
       res = (*playerObj)->Realize(playerObj, XA_BOOLEAN_FALSE);
       res = (*playerObj)->GetInterface(playerObj, XA_IID_PLAY, &playerPlayItf);
       res = (*playerObj)->GetInterface(playerObj, XA_IID_ANDROIDBUFFERQUEUESOURCE, &playerBQItf);
       res = (*playerBQItf)->SetCallbackEventsMask(playerBQItf, XA_ANDROIDBUFFERQUEUEEVENT_PROCESSED);
       res = (*playerBQItf)->RegisterCallback(playerBQItf, AndroidBufferQueueCallback, NULL);
       if (!enqueueInitialBuffers(JNI_FALSE)) {
           return JNI_FALSE;
       }
       res = (*playerPlayItf)->SetPlayState(playerPlayItf, XA_PLAYSTATE_PAUSED);
       res = (*playerPlayItf)->SetPlayState(playerPlayItf, XA_PLAYSTATE_PLAYING);
       return JNI_TRUE;
    }
    ```

    `AndroidBufferQueueCallback`是注册的回调函数，用于向缓冲区重新填充媒体数据或处理命令:

    ```cpp
    XAresult AndroidBufferQueueCallback(XAAndroidBufferQueueItf caller, void *pCallbackContext, void *pBufferContext,  void *pBufferData, XAuint32 dataSize,  XAuint32 dataUsed, const XAAndroidBufferItem *pItems, XAuint32 itemsLength) {
       XAresult res;
       int ok;
       ok = pthread_mutex_lock(&mutex);
       if (discontinuity) {
           if (!reachedEof) {
               res = (*playerBQItf)->Clear(playerBQItf);
               rewind(file);
                (void) enqueueInitialBuffers(JNI_TRUE);
           }
           discontinuity = JNI_FALSE;
           ok = pthread_cond_signal(&cond);
           goto exit;
       }
       if ((pBufferData == NULL) && (pBufferContext != NULL)) {
           const int processedCommand = *(int *)pBufferContext;
           if (kEosBufferCntxt == processedCommand) {
               goto exit;
           }
       }
       if (reachedEof) {
           goto exit;
       }
       size_t nbRead;
       size_t bytesRead;
       bytesRead = fread(pBufferData, 1, BUFFER_SIZE, file);
       if (bytesRead > 0) {
           if ((bytesRead % MPEG2_TS_PACKET_SIZE) != 0) {
               LOGI(2, "Dropping last packet because it is not whole");
           }
           size_t packetsRead = bytesRead / MPEG2_TS_PACKET_SIZE;
           size_t bufferSize = packetsRead * MPEG2_TS_PACKET_SIZE;
           res = (*caller)->Enqueue(caller, NULL, pBufferData, bufferSize, NULL, 0);
       } else {
           XAAndroidBufferItem msgEos[1];
           msgEos[0].itemKey = XA_ANDROID_ITEMKEY_EOS;
           msgEos[0].itemSize = 0;
           res = (*caller)->Enqueue(caller, (void *)&kEosBufferCntxt, NULL, 0, msgEos, sizeof(XAuint32)*2);
           reachedEof = JNI_TRUE;
       }
    exit:
       ok = pthread_mutex_unlock(&mutex);
       return XA_RESULT_SUCCESS;
    }
    ```

5.  在`jni`文件夹中添加一个`Android.mk`文件，内容如下:

    ```cpp
    LOCAL_PATH := $(call my-dir)
    include $(CLEAR_VARS)
    LOCAL_MODULE    := OpenMAXSLDemo
    LOCAL_SRC_FILES := OpenMAXSLDemo.c
    LOCAL_LDLIBS := -llog
    LOCAL_LDLIBS    += -landroid
    LOCAL_LDLIBS    += -lOpenMAXAL
    include $(BUILD_SHARED_LIBRARY)
    ```

6.  我们可以使用`samples/native-media/`目录中的`NativeMedia.ts`视频 文件进行测试。以下命令可用于将视频文件放入测试安卓设备的`/sdcard/`目录:

    ```cpp
    $ adb push NativeMedia.ts /sdcard/
    ```

7.  Build and start the Android application. We can see the GUI as shown in the following screenshot:

    ![How to do it...](graphics/1505_07_14.jpg)

    我们可以按**播放**开始播放视频。

## 它是如何工作的...

在这个食谱中，我们使用 OpenMAX AL 库实现了一个 简单的视频播放器。

### 使用和构建 OpenMAX AL 多媒体库:

为了调用应用编程接口函数，我们必须在代码中添加下面一行 :

```cpp
#include <OMXAL/OpenMAXAL.h>
```

如果我们也使用安卓特有的功能，我们应该包括另一个标题:

```cpp
#include <OMXAL/OpenMAXAL_Android.h>
```

在`Android.mk`文件中，我们必须添加以下一行链接到 OpenMAX AL 多媒体库:

```cpp
LOCAL_LDLIBS += libOpenMAXAL
```

### OpenMAX AL 视频播放

我们的示例项目是原生媒体项目的简化版本，附带安卓 NDK 系统。下图说明了应用程序的工作原理:

![OpenMAX AL video playback](graphics/1505_07_15.jpg)

在我们的代码中，我们在`naCreateEngine` 函数中创建并实现了引擎和输出混合对象。在`naCreateStreamingMediaPlayerfunction`功能中，我们创建并实现了一个媒体播放器对象，其中音频数据接收器设置为输出混合，视频数据接收器设置为本机显示，数据源设置为安卓缓冲队列。

当缓冲区被消耗时，回调函数`AndroidBufferQueueCallback`被调用，在那里我们用来自`NativeMedia.ts`文件的数据重新填充缓冲区，并将其排入缓冲区队列。

## 还有更多....

OpenMAX AL 是一个复杂的库。当使用 OpenMAX AL 开发应用程序时，该规范是一个很好的参考，并且可以在安卓 NDK 上使用。安卓 NDK 还附带了一个本地媒体的例子，这是一个如何使用应用编程接口的好例子。