- en: 'Chapter 4. Visual and Audio Input: Camera and Microphone Access'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Detecting camera and microphone support
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the traditional camera API to save a captured image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the Mobile CameraUI API to save a captured photograph
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the Mobile CameraUI API to save a captured video
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the device microphone to monitor audio sample data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recording microphone audio sample data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Camera and microphone are standard accessories on most mobile devices and Android
    devices are no exception to this. The present chapter will cover everything from
    accessing the camera and taking photos, recording video data, and encoding raw
    audio captured from the device microphone and encoding it to WAV or MP3 for use
    on other platforms and systems.
  prefs: []
  type: TYPE_NORMAL
- en: All of the recipes in this chapter are represented as pure ActionScript 3 classes
    and are not dependent upon external libraries or the Flex framework. Therefore,
    we will be able to use these examples in any IDE we wish.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting camera and microphone support
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Nearly all Android devices come equipped with camera hardware for capturing
    still images and video. Many devices now have both front and rear-facing cameras.
    It is important to know whether the default device camera is usable through our
    application. We should never assume the availability of certain hardware items,
    no matter how prevalent across devices.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, we will want to be sure to have access to the device microphone as
    well, when capturing video or audio data.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will determine which audio and video APIs are available to us on our Android
    device:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the following classes into your project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Declare a `TextField` and `TextFormat` object pair to allow visible output
    upon the device:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will now set up our `TextField`, apply a `TextFormat`, and add the `TextField`
    to the `DisplayList`. Here, we create a method to perform all of these actions
    for us:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, we must check the `isSupported` property of each of these objects. We create
    a method here to perform this across all three and write results to a `TextField:`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We now know the capabilities of video and audio input for a particular device
    and can react accordingly:![How to do it...](img/1420_04_01.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Each of these three classes has a property `isSupported`, which we may invoke
    at any time to verify support on a particular Android device. The traditional
    `Camera` and mobile-specific `CameraUI` both refer to the same hardware camera,
    but are entirely different classes for dealing with the interaction between Flash
    and the camera itself, as `CameraUI` relies upon the default device camera applications
    to do all the capturing, and `Camera` works exclusively within the Flash environment.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The traditional `Microphone` object is also supported in this manner.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is important to note that even though many Android devices come equipped
    with more than one camera, only the primary camera (and microphone) will be exposed
    to our application. Support for multiple cameras and other sensors will likely
    be added to the platform as Android evolves.
  prefs: []
  type: TYPE_NORMAL
- en: Using the traditional camera API to save a captured image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When writing applications for the web through Flash player, or for a desktop
    with AIR, we have had access to the `Camera` class through ActionScript. This
    allows us to access different cameras attached to whatever machine we are using.
    On Android, we can still use the `Camera` class to access the default camera on
    the device and access the video stream it provides for all sorts of things. In
    this example, we will simply grab a still image from the `Camera` feed and save
    it to the Android `CameraRoll`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will construct a `Video` object to bind the `Camera` stream to, and use
    `BitmapData` methods to capture and then save our rendered image using the mobile
    `CameraRoll` API:'
  prefs: []
  type: TYPE_NORMAL
- en: 'At a minimum, we need to import the following classes into our project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now we must declare the object instances necessary for camera access and file
    reference:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Initialize a `Video` object, passing in the desired width and height, and add
    it to the `DisplayList:`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Initialize a `Camera` object and employ `setMode` to specify width, height,
    and frames per second before attaching the `Camera` to our `Video` on the `DisplayList:`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will now register a `TouchEvent` listener of type `TOUCH_TAP` to the `Stage`.
    This will enable the user to take a snapshot of the camera display by tapping
    the device screen:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: To capture an image from the camera feed, we will initialize our `BitmapData`
    object, matching the width and height of our `Video` object, and employ the `draw`
    method to translate the `Video` pixels to `BitmapData`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To save our acquired image to the device, we must initialize a `CameraRoll`
    object and invoke `addBitmapData()`, passing in the `BitmapData` object we have
    created using `Video` object pixels. We will also determine whether or not this
    device supports the `addBitmapData()` method by verifying `CameraRoll.supportsAddBitmapData`
    is equal to `true:`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![How to do it...](img/1420_04_02.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: If we now check our Android Gallery, we will find the saved image:![How to do
    it...](img/1420_04_03.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most of this is performed exactly as it would be with normal Flash Platform
    development on the desktop. Attach a `Camera` to a `Video`, add the `Video` to
    the `DisplayList`, and then do whatever you need for your particular application.
    In this case, we simply capture what is displayed as `BitmapData`.
  prefs: []
  type: TYPE_NORMAL
- en: The `CameraRoll` class, however, is specific to mobile application development
    as it will always refer to the directory upon which the device camera stores the
    photographs it produces. If you want to save these images within a different directory,
    we could use a `File` or `FileReference` object to do so, but this involves more
    steps for the user.
  prefs: []
  type: TYPE_NORMAL
- en: Note that while using the `Camera` class, the hardware orientation of the camera
    is landscape. We can deal with this by either restricting the application to landscape
    mode, or through rotations and additional manipulation as we've performed in our
    example class. We've applied a 90 degree rotation to the image in this case using
    `videoHolder.rotation` to account for this shift when reading in the `BitmapData`.
    Depending on how any specific application handles this, it may not be necessary
    to do so.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Other use cases for the traditional Camera object are things such as sending
    a video stream to Flash Media Server for live broadcast, augmented reality applications,
    or real-time peer to peer chat.
  prefs: []
  type: TYPE_NORMAL
- en: See also...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In order to access the camera and storage, we will need to add some Android
    permissions for `CAMERA` and `WRITE_EXTERNAL_STORAGE`. Refer to [Chapter 11](ch11.html
    "Chapter 11. Final Considerations: Application Compilation and Distribution"),
    *Final Considerations: Application Compilation and Distribution* for information
    on how to go about this.'
  prefs: []
  type: TYPE_NORMAL
- en: Using the Mobile CameraUI API to save a captured photograph
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using the new `CameraUI` API (available in the mobile AIR SDK), we can perform
    and alternative capture process to the normal `Camera` API. The `Mobile CameraUI`
    class will make use of the default Android camera application, alongside our custom
    app, to capture a photograph.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will set up a `CameraUI` object to invoke the native Android camera to capture
    a photograph:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the following classes into your project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Declare aTextField and `TextFormat` object pair to allow visible output upon
    the device. A `CameraUI` object must also be declared for this example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will now set up our `TextField`, apply a `TextFormat`, and add the `TextField`
    to the `DisplayList`. Here, we create a method to perform all of these actions
    for us:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate a new `CameraUI` instance, which will be used to launch the device
    camera application and return file information back to us. If the `CameraUI` object
    is not supported on a particular device, a message is output to our `TextField`
    indicating this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add an event listener to the `CameraUI` object so that we know when the capture
    is complete. We will also register a touch event on the `Stage` to initiate the
    capture:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To employ the default camera application on our Android device, we will need
    to invoke the `launch` method, passing in the `MediaType.IMAGE` constant to specify
    that we wish to capture a photograph:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, the default Android camera will initialize, allowing the user to capture
    a photograph. Once the user hits **OK**, focus will return to our application.![How
    to do it...](img/1420_04_04.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, once we complete the capture process, an event of type `MediaEvent.COMPLETE`
    will fire, invoking our `photoReady` method. From this, we can ascertain certain
    details about our captured photograph.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The output will look something like this:![How to do it...](img/1420_04_05.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Invoking the `CameraUI.launch` method will request the Android device to open
    the default camera application and allow the user to take a photograph. Upon completing
    the capture process and confirming the captured photograph, focus is then returned
    to our application along with a set of data about the new file contained within
    the `MediaEvent.COMPLETE` event object.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, our application can do all sorts of things with the data returned,
    or even open the file within the application, assuming that the file type can
    be loaded and displayed by the runtime.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The default camera application will not load if the device does not have a storage
    card mounted. It is also important to note that if the device becomes low on memory
    during the capture process, Android may terminate our application before the process
    is complete.
  prefs: []
  type: TYPE_NORMAL
- en: See also...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will discuss the display of images through an AIR for Android application
    in [Chapter 5](ch05.html "Chapter 5. Rich Media Presentation: Working with Images,
    Video, and Audio"): *Rich Media Presentation: Working with Images, Video, and
    Audio.*'
  prefs: []
  type: TYPE_NORMAL
- en: Using the Mobile CameraUI API to save a captured video
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using the new `CameraUI` API (available in the mobile AIR SDK) we can perform
    and alternative capture process to the normal `Camera` API. The mobile `CameraUI`
    class will make use of the default Android camera application, alongside our custom
    app to capture a video.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will set up a `CameraUI` object to invoke the native Android camera to capture
    a video:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the following classes into your project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Declare a `TextField` and `TextFormat` object pair to allow visible output
    upon the device. A `CameraUI` object must also be declared for this example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will now set up our `TextField`, apply a `TextFormat`, and add the `TextField`
    to the `DisplayList`. Here, we create a method to perform all of these actions
    for us:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Instantiate a new `CameraUI` instance, which will be used to launch the device
    camera application and return file information back to us. If the `CameraUI` object
    is not supported on a particular device, a message is output to our `TextField`
    indicating this.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add an event listener to the `CameraUI` object so that we know when the capture
    is complete. We will also register a touch event on the `Stage` to initiate the
    capture:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To employ the default camera application on our Android device, we will need
    to invoke the `launch` method, passing in the `MediaType.VIDEO` constant to specify
    that we wish to capture a video file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, the default Android camera will initialize, allowing the user to take some
    video. Once the user hits **OK**, focus will return to our application:![How to
    do it...](img/1420_04_06.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Finally, once we complete the capture process, an event of type `MediaEvent.COMPLETE`
    will fire, invoking our `videoReady` method. From this, we can ascertain certain
    details about our captured video file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The output will look something like this:![How to do it...](img/1420_04_07.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Invoking the `CameraUI.launch` method will request that the Android device open
    the default camera application and allow the user to capture some video. Upon
    completing the capture process and confirming the captured video file, focus is
    then returned to our application along with a set of data about the new file contained
    within the `MediaEvent.COMPLETE` event object.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, our application can do all sorts of things with the data returned,
    or even open the file within the application, assuming that the file type can
    be loaded and displayed by the runtime. This is very important when it comes to
    video as certain devices will use a variety of codecs to encode the captured video,
    not all of them Flash Platform compatible.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The default camera application will not load if the device does not have a storage
    card mounted. It is also important to note that if the device becomes low on memory
    during the capture process, Android may terminate our application before the process
    is complete.
  prefs: []
  type: TYPE_NORMAL
- en: Also, there are many other events aside from `MediaEvent.COMPLETE` that we can
    use in such a process. For instance, register an event listener of type `Event.CANCEL`
    in order to react to the user canceling a video save.
  prefs: []
  type: TYPE_NORMAL
- en: See also...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will discuss the playback of video files through an AIR for Android application
    in [Chapter 5](ch05.html "Chapter 5. Rich Media Presentation: Working with Images,
    Video, and Audio").'
  prefs: []
  type: TYPE_NORMAL
- en: Using the device microphone to monitor audio sample data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By monitoring the sample data being returned from the Android device microphone
    through the ActionScript `Microphone` API, we can gather much information about
    the sound being captured, and perform responses within our application. Such input
    can be used in utility applications, learning modules, and even games.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will set up an event listener to respond to sample data reported through
    the `Microphone` API:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the following classes into your project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Declare a `TextField` and `TextFormat` object pair to allow visible output
    upon the device. A `Microphone` object must also be declared for this example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will now set up our `TextField`, apply a `TextFormat`, and add the `TextField`
    to the `DisplayList`. Here, we create a method to perform all of these actions
    for us:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we must instantiate our `Microphone` object and set it up according to
    our needs and preferences with adjustments to `codec, rate, silenceLevel`, and
    so forth. Here we use `setSilenceLevel()` to determine what the minimum input
    level our application should consider to be "sound" and the `rate` property is
    set to **44**, indicating that we will capture audio data at a rate of 44kHz.
    Setting the `setLoopBack ()` property to false will keep the captured audio from
    being routed through the device speaker:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once we have instantiated our `Microphone` object, we can then register a variety
    of event listeners. In this example, we''ll be monitoring audio sample data from
    the device microphone, so we will need to register our listener for the `SampleDataEvent.SAMPLE_DATA`
    constant:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As the `Microphone` API generates sample data from the Android device input,
    we can now respond to this in a number of ways, as we have access to information
    about the `Microphoneobject` itself, and more importantly, we have access to the
    sample bytes with which we can perform a number of advanced operations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The output will look something like this. The first three values are taken from
    the `Microphone` itself, the second three from `Microphone` sample data:![How
    to do it...](img/1420_04_08.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we instantiate a `Microphone` object and register a `SampleDataEvent.SAMPLE_DATA`
    event listener, we can easily monitor various properties of our Android device
    microphone and the associated sample data being gathered. We can then respond
    to that data in many ways. One example would be to move objects across the `Stage`
    based upon the `Microphone.activityLevel` property. Another example would be to
    write the sample data to a `ByteArray` for later analysis.
  prefs: []
  type: TYPE_NORMAL
- en: What do all these properties mean?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`activityLevel:` This is a measurement indicating the amount of sound being
    received'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`codec:` This indicates the codec being used: Nellymoser or Speex'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gain:` This is an amount of boosting provided by the microphone to the sound
    signal'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bytesAvailable:` This reveals the number of bytes from the present position
    until the end of our sample data `byteArray`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`length:` Lets us know the total length of our sample data `byteArray`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`position:` This is the current position, in bytes, within our sample data
    `byteArray`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See also...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In order to access the microphone, we will need to add some Android permissions
    for `RECORD_AUDIO`. Refer to [Chapter 11](ch11.html "Chapter 11. Final Considerations:
    Application Compilation and Distribution") for information on how to go about
    this.'
  prefs: []
  type: TYPE_NORMAL
- en: Recording Microphone Audio Sample Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most fundamental things a developer would want to be able to do with
    audio sample data gathered from an Android microphone, would be to capture the
    data and use it in some way within an application. This recipe will demonstrate
    how to preserve and play back captured microphone audio sample data.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will employ an event listener to respond to sample data reported through
    the `Microphone` API by writing captured audio data to a `ByteArray` and then
    playing it back internally through the `Sound` object:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the following classes into your project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Declare a `TextField` and `TextFormat` object pair to allow visible output
    upon the device. A `Microphone` object must also be declared for this example.
    To store and play back the sample data, we will need to declare a `ByteArray`,
    along with a `Sound` and `SoundChannel` pair:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will now set up our `TextField`, apply a `TextFormat`, and add the `TextField`
    to the `DisplayList`. Here, we create a method to perform all of these actions
    for us:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, instantiate a `Microphone` object and set it up according to our needs
    and preferences with adjustments to `codec, rate, silenceLevel`, and so forth.
    Here we use `setSilenceLevel()` to determine what the minimum input level our
    application should consider to be "sound" and the `rate` property is set to **44**,
    indicating that we will capture audio data at a rate of 44kHz. Setting the `setLoopBack
    ()` property to false will keep the captured audio from being routed through the
    device speaker. We''ll also instantiate a `ByteArray` to hold all of our audio
    samples as they are intercepted:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once we have instantiated our `Microphone` and `ByteArray` objects, we can
    then register an event listener to enable touch interactions. A simple tap will
    suffice:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once recording has been invoked by the user, we''ll be monitoring audio sample
    data from the device microphone, so will need to register our listener for the
    `SampleDataEvent.SAMPLE_DATA` constant:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As the `Microphone` API generates sample data from the Android device input,
    we have access to the audio sample data bytes, which we can write to a `ByteArray`
    for later use:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To stop recording, we will need to remove the `SampleDataEvent.SAMPLE_DATA`
    event listener from our `Microphone` object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To prepare for playback, we will instantiate a new `Sound` object and register
    a `SampleDataEvent.SAMPLE_DATA` event upon it just as we had done for the `Microphone`
    object previously. We will also instantiate a `SoundChannel` object and invoke
    the `play()` method of our `Sound` object to play back the captured `Microphone`
    audio:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Once we invoke the `play()` method upon our `Sound` object, it will begin gathering
    generated sample data from a method called `onSampleDataRequest`. We need to create
    this method now, and allow it to loop over the bytes we previously wrote to our
    `ByteArray` object. This is, effectively, the inverse of our capture process.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In order to provide proper playback within our application we must provide between
    2048 and 8192 samples of data. It is recommended to use as many samples as possible,
    but this will also depend upon the sample frequency.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that we invoke `writeFloat()` twice within the same loop because we need
    our data expressed in stereo pairs, one for each channel.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'When using `writeBytes()` in this example, we are actually channeling sound
    data back out through our `SampleDataEvent` and through a `Sound` object, thus
    enabling the application to produce sound:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Output to our `TextField` will change depending upon the current application
    state:![How to do it...](img/1420_04_09.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we instantiate a `Microphone` object and register a `SampleDataEvent.SAMPLE_DATA`
    event listener, we can easily monitor the associated sample data being gathered
    and write this data to a `ByteArray` for later playback. As new samples come in,
    more data is added to the `ByteArray`, building up the sound data over time.
  prefs: []
  type: TYPE_NORMAL
- en: By registering a `SampleDataEvent.SAMPLE_DATA` event listener to a `Sound` object,
    we instruct it to actively seek audio data generated from a specific method as
    soon as we invoke `play()`. In our example, we move through the constructed `ByteArray`
    and send audio data back out through this method, effectively playing back the
    recorded audio through the `Sound` object and associated `SoundChannel`.
  prefs: []
  type: TYPE_NORMAL
- en: See also...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The use of bytes within ActionScript is a complex subject. To read more about
    this topic, we recommend Thibault Imbert's book *"What can you do with bytes?"*,
    which is freely available from [http://www.bytearray.org/?p=711](http://www.bytearray.org/?p=711).
  prefs: []
  type: TYPE_NORMAL
- en: 'To read recipes concerning the playback of audio files, have a look at [Chapter
    5](ch05.html "Chapter 5. Rich Media Presentation: Working with Images, Video,
    and Audio"). For information on saving captured audio data to the Android device,
    refer to [Chapter 8:](ch08.html "Chapter 8. Abundant Access: File System and Local
    Database") *Abundant Access: File System and Local Database.*'
  prefs: []
  type: TYPE_NORMAL
