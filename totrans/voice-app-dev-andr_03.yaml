- en: Chapter 3. Speech Recognition
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章. 语音识别
- en: 'Have you ever tapped through several menus and options on your device until
    you were able to do what you wanted? Have you ever wished you could just say some
    words and make it work? This chapter looks at **Automatic Speech Recognition**
    (**ASR**), the process that converts spoken words to written text. The topics
    covered are as follows:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否曾在设备上点击多个菜单和选项，直到你能够完成你想要的操作？你是否希望只需说几个字就能让它工作？本章探讨的是**自动语音识别**（**ASR**），它将说出的单词转换为书面文字的过程。涵盖的主题包括以下内容：
- en: The technology of speech recognition
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音识别技术
- en: Using Google speech recognition
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用谷歌语音识别
- en: Developing applications with the Google speech recognition API
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用谷歌语音识别API开发应用
- en: By the end of this chapter, you should have a good understanding of the issues
    involved in using speech recognition in an app and should be able to develop simple
    apps using the Google speech API.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你应该能够很好地理解在应用中使用语音识别所涉及的问题，并应该能够使用谷歌语音API开发简单的应用程序。
- en: The technology of speech recognition
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 语音识别技术
- en: 'The following are the two main stages in speech recognition:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是语音识别的两个主要阶段：
- en: '**Signal processing**: This stage involves capturing the words spoken into
    a microphone and using an **analogue-to-digital converter** (**ADC**) to translate
    it into digital data that can be processed by the computer. The ADC processes
    the digital data to remove noise and perform other processes such as echo cancellation
    in order to be able to extract those features that are relevant for speech recognition.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信号处理**：这一阶段包括将麦克风录入的单词通过**模拟-数字转换器**（**ADC**）转换成计算机可以处理的数字数据。ADC处理数字数据以去除噪音，并执行其他如回声消除等过程，以便能够提取对语音识别有关键作用的特点。'
- en: '**Speech recognition**: The signal is split into minute segments that are matched
    against the phonemes of the language to be recognized. Phonemes are the smallest
    unit of speech, roughly equivalent to the letters of the alphabet. For example,
    the phonemes in the word cat are */k/*, */æ/*, and */t/*. In English, for example,
    there are around 40 phonemes, depending on which variety of English is being spoken.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语音识别**：信号被分割成微小的片段，与待识别语言的音素进行匹配。音素是语音的最小单位，大致相当于字母表中的字母。例如，单词"cat"中的音素是
    */k/*, */æ/*, 和 */t/*。在英语中，例如，大约有40个音素，这取决于所讲英语的变体。'
- en: The most successful approach to speech recognition has been to model speech
    statistically so that the outcome of the process is a series of guesses (or hypotheses)
    as to what the user might have said, ranked according to the computed probability.
    Complex probabilistic functions are used to perform this statistical modeling.
    The most commonly used among these is the *Hidden Markov Model*, but neural networks
    are also used and in some cases, hybrid processes using a combination of these
    two approaches. The models are tuned through a process of training using large
    amounts of training data. Usually, hundreds to thousands of audio hours are employed
    in order to handle the variability and complexity of human speech. The result
    is an *acoustic model* that represents the different ways in which the sounds
    and words of a language can be pronounced.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在语音识别中最成功的方法是统计建模语音，这样处理的结果是一系列猜测（或假设）用户可能说的话，并根据计算出的概率进行排序。这一统计建模使用复杂的概率函数。其中最常用的模型是*隐马尔可夫模型*，但神经网络也被使用，有时还使用这两种方法的混合过程。这些模型通过使用大量训练数据的训练过程进行调优。通常，需要使用数百到数千小时的音频来处理人类语音的变异性和复杂性。结果是产生了一个表示语言中声音和单词不同发音方式的*声学模型*。
- en: On its own, the acoustic model is not sufficient for high performance speech
    recognition. An additional part of a speech recognition system is another statistical
    model, the *language model*. This model contains knowledge about permissible sequences
    of words and which words are more likely in a given sequence. For example, although
    acoustically the words *to* and *two* sound the same, the former is more likely
    in the phrase *I went to the shops* and the latter in the phrase *I bought two
    shirts*. The language model would help to return the correct word in each phrase.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅依靠声学模型对于高性能的语音识别是不够的。语音识别系统的另一个部分是另一个统计模型，即*语言模型*。这个模型包含了关于允许的单词序列和给定序列中哪些单词更可能出现的知识。例如，尽管从声学角度来说，*to*和*two*听起来是一样的，但在短语*I
    went to the shops*中前者更可能出现，在短语*I bought two shirts*中则是后者。语言模型有助于返回每个短语中正确的单词。
- en: The output of speech recognition is a list of recognition results (known as
    the *N-best list*) ranked according to the confidence the recognizer has that
    the recognition is correct, in an interval from 0 to 1\. A value close to 1.0
    indicates high confidence that the recognition is correct, while values closer
    to 0.0 indicate low confidence. The N-best list and the confidence scores are
    useful as it may be the case that the first-best recognized string is not what
    the user actually said and that the alternatives might offer a result that is
    more appropriate. The confidence scores are also useful as they can provide a
    basis for deciding how the system should continue, for example, whether to confirm
    the recognized phrase or not.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 语音识别的输出是根据识别器对识别正确性的置信度（从0到1的区间）排列的一系列识别结果（称为*N-best列表*）。接近1.0的值表示对识别正确性有很高的置信度，而接近0.0的值表示置信度较低。N-best列表和置信度分数很有用，因为可能的情况是，首选识别的字符串并不是用户实际所说的内容，而其他选项可能提供更合适的结果。置信度分数也很有用，因为它们可以为决定系统应该如何继续提供依据，例如，是否确认已识别的短语。
- en: Using Google speech recognition
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用谷歌语音识别
- en: 'Speech recognition services have been available on Android devices since Android
    2.1 (API level 7). One place where recognition is available is via a microphone
    icon on the Android keyboard. Clicking on the microphone button activates the
    Google speech recognition service, as shown in the following screenshot. The red
    microphone and the textual prompt indicate that the system is expecting some speech:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 自从Android 2.1（API级别7）起，语音识别服务就已经在Android设备上可用。其中一个可以使用识别功能的地方就是Android键盘上的麦克风图标。点击麦克风按钮激活谷歌语音识别服务，如下面的截图所示。红色的麦克风和文字提示表明系统正在等待接收语音：
- en: '![Using Google speech recognition](img/5297_03_01.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![使用谷歌语音识别](img/5297_03_01.jpg)'
- en: If no speech is detected, a re-prompt dialog is generated, asking the user to
    try to speak again. Another possible situation is where no suitable match can
    be found for the user's spoken input. In this case, the screen displays the message
    **No matches found**. Finally, the message **Connection problem** is displayed
    when no internet connection is available.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有检测到语音，系统会生成一个重新提示对话框，要求用户再次尝试说话。另一种可能是无法为用户的语音输入找到合适的匹配项。在这种情况下，屏幕会显示**未找到匹配项**的消息。最后，当没有可用的网络连接时，会显示**连接问题**的消息。
- en: The parameters of the on-board speech recognition services can be adjusted either
    through **Settings** | **Language and input** | **Speech** | **Voice Search**
    or, depending on the device, by clicking on the **Tool** icon at the top hand
    corner of the screen. A number of available languages will be presented. Checking
    for the availability of languages and also selecting a language can be done programmatically.
    This will be covered in [Chapter 7](ch07.html "Chapter 7. Multilingual and Multimodal
    Dialogs"), *Multilingual and Multimodal Dialogs*.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过**设置** | **语言和输入** | **语音** | **语音搜索**调整内置语音识别服务的参数，或者根据设备的不同，点击屏幕右上角的**工具**图标。会展示出多种可用的语言。检查语言的可用性以及选择语言也可以通过编程实现。这将在[第7章](ch07.html
    "第7章. 多语言和多模态对话")，*多语言和多模态对话*中进行介绍。
- en: Developing applications with the Google speech recognition API
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用谷歌语音识别API开发应用
- en: The components of the Google speech API (package `android.speech`) are documented
    at [http://developer.android.com/reference/android/speech/package-summary.html](http://developer.android.com/reference/android/speech/package-summary.html).
    Interfaces and classes are listed here and further details can be obtained by
    clicking on them.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌语音API（包`android.speech`）的组件在[http://developer.android.com/reference/android/speech/package-summary.html](http://developer.android.com/reference/android/speech/package-summary.html)进行了文档化。这里列出了接口和类，点击它们可以获得更多详细信息。
- en: 'There are two ways in which speech recognition can be carried out on an Android
    device: based solely on a `RecognizerIntent` approach, or by creating an instance
    of `SpeechRecognizer`. The former provides an easy-to-program mechanism with which
    it is possible to create apps that use speech recognition by starting the Intent
    class and processing its results. The apps following this scheme will present
    a dialog providing feedback to the user on whether the ASR is ready, or about
    different errors during the recognition process. Using `SpeechRecognizer` provides
    developers with different notifications of recognition-related events, thus allowing
    a more fine-grained processing of the speech recognition process. With this approach
    the dialog is not shown, providing more control for the developer on the app''s
    GUI.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在Android设备上有两种进行语音识别的方法：仅基于`RecognizerIntent`的方法，或者创建`SpeechRecognizer`的实例。前者提供了一个易于编程的机制，通过启动Intent类并处理其结果，可以创建使用语音识别的应用程序。按照此方案的应用程序将显示一个对话框，为用户提供关于ASR是否准备就绪或在识别过程中出现不同错误的信息反馈。使用`SpeechRecognizer`为开发人员提供了关于识别相关事件的不同通知，从而允许更细致地处理语音识别过程。这种方法不会显示对话框，为开发人员在应用程序GUI上提供更多控制。
- en: 'In the following sections, we will present two apps (`ASRWithIntent` and `ASRWithLib`)
    that recognize what the user says and present the results for the recognition
    in the form of an N-best list with confidence scores. In essence, they are the
    same application but they have been developed following the two different approaches
    described: `ASRWithIntent` uses the `RecognizerIntent` approach, and `ASRWithLib`
    the `SpeechRecognizer` approach which we have programmed in the ASRLib library
    (`sandra.libs.asr.asrlib` in the code bundle).'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下章节中，我们将介绍两个应用程序（`ASRWithIntent`和`ASRWithLib`），它们识别用户说的话并以N-best列表的形式展示识别结果及置信度得分。实际上，它们是相同的应用程序，但是它们是按照前面描述的两种不同方法开发的：`ASRWithIntent`使用`RecognizerIntent`方法，而`ASRWithLib`使用我们在ASRLib库中编程的`SpeechRecognizer`方法（代码包中的`sandra.libs.asr.asrlib`）。
- en: ASRWithIntent app
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 带有Intent的ASR应用
- en: 'This simple app illustrates the following:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单的应用程序说明了以下内容：
- en: The user selects the parameters for speech recognition.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户选择语音识别的参数。
- en: The user presses a button and says some words.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户按下按钮并说一些话。
- en: The words recognized are displayed in a list along with their confidence scores.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 识别出的词语及其置信度得分以列表形式显示。
- en: 'In the opening screen, there is a button with the message **Press the button
    to speak**. When the user presses the button, speech recognition is launched using
    the parameters selected by the user. The results of an instance of activating
    speech recognition and saying the words *What''s the weather like in Belfast*
    are shown in the following screenshot:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在打开的屏幕上，有一个带有消息**按下按钮说话**的按钮。当用户按下按钮时，将启动语音识别功能，使用用户选择的参数。激活语音识别实例并说出*贝尔法斯特的天气如何*的词组的结果在下图中显示：
- en: '![ASRWithIntent app](img/5297_03_02_correct.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![带有Intent的ASR应用](img/5297_03_02_correct.jpg)'
- en: 'The button that the user presses to start speech recognition is set up through
    reference to the button specified in `asrwithintent.xml`, which you can find in
    the code bundle (in the `res/layout` folder of the `ASRWithIntent` project):'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 用户按下启动语音识别的按钮是通过引用`asrwithintent.xml`中指定的按钮设置的，你可以在代码包中找到它（在`ASRWithIntent`项目的`res/layout`文件夹中）：
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: When the user presses the button, the method `listen()` is invoked in which
    the details of `RecognizerIntent` are set. In `ASRWithIntent`, speech recognition
    is supported by the class `RecognizerIntent` by sending an Intent with the action
    `ACTION_RECOGNIZE_SPEECH`, using the method `startActivityForResult(Intent,int)`,
    where the `int` value is a request code defined by the developer. If it is greater
    than 0, this code will be returned in `onActivityResult()` when the activity exits.
    The request code serves as an identifier to distinguish which intent generated
    a certain result from the different intents that could have been invoked within
    the application.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户按下按钮时，将调用`listen()`方法，在其中设置`RecognizerIntent`的详细信息。在`ASRWithIntent`中，通过发送一个带有`ACTION_RECOGNIZE_SPEECH`动作的Intent来支持语音识别，使用`startActivityForResult(Intent,int)`方法，其中`int`值是由开发者定义的请求代码。如果它大于0，当活动退出时，此代码将在`onActivityResult()`中返回。请求代码作为标识符，用于区分在应用程序中可能调用的不同意图产生的特定结果。
- en: 'The following code starts an activity to recognize speech:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码启动了一个识别语音的活动：
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'As shown in the code, there are a number of extras associated with `ACTION_RECOGNIZE_SPEECH`.
    One of these, `EXTRA_LANGUAGE_MODEL`, is required. The others are optional. As
    its name implies, `EXTRA_LANGUAGE_MODEL` specifies the language model to be used
    in the recognition process. The following two options are supported by it:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 正如代码所示，与`ACTION_RECOGNIZE_SPEECH`关联有几个额外的参数。其中一个是必需的，即`EXTRA_LANGUAGE_MODEL`。其他的是可选的。顾名思义，`EXTRA_LANGUAGE_MODEL`指定了在识别过程中要使用的语言模型。它支持以下两个选项：
- en: '`LANGUAGE_MODEL_FREE_FORM`: This language model is based on free-form speech
    recognition and is used to recognize free-form speech, for example, in the dictation
    of an e-mail.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LANGUAGE_MODEL_FREE_FORM`：这个语言模型基于自由形式的语音识别，用于识别自由形式的语音，例如，在电子邮件的口述中。'
- en: '`LANGUAGE_MODEL_WEB_SEARCH`: This language model is based on web search terms
    and is used to model more restricted forms of input such as shorter, search-like
    phrases, for example, *flights to London*, *weather in Madrid*, and so on.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LANGUAGE_MODEL_WEB_SEARCH`：这个语言模型基于网络搜索词汇，用于模拟更为受限的输入形式，如较短的、类似搜索的短语，例如，*飞往伦敦*，*马德里的天气*等等。'
- en: As can be observed, both options imply quite unrestricted inputs. To build an
    app in which only certain keywords are accepted, or to use recognition grammars,
    currently it is necessary to post-process the recognition results to match them
    against the expected patterns. Some examples on how to do this will be shown in
    [Chapter 6](ch06.html "Chapter 6. Grammars for Dialog"), *Grammars for Dialog*.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 可以观察到，这两个选项都意味着相当不受限制的输入。要构建一个只接受特定关键词的应用程序，或者使用识别语法，目前需要处理识别结果，以匹配预期的模式。关于如何执行此操作的一些示例将在[第6章](ch06.html
    "第6章. 对话语法")，*对话语法*中展示。
- en: 'The other extras are described in the Android documentation for the `RecognizerIntent`
    class. The following are some of the more commonly used optional extras:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 其他额外的参数在Android文档的`RecognizerIntent`类中有描述。以下是一些更常用的可选额外参数：
- en: '`EXTRA_PROMPT`: This provides a text prompt that is shown to users when they
    are asked to speak.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`EXTRA_PROMPT`：这提供了一个文本提示，当要求用户说话时向用户展示。'
- en: '`EXTRA_MAX_RESULTS`: This integer value specifies a limit on the maximum number
    of results to be returned. If omitted, the recognizer will choose how many results
    to return. The results are the different possible texts corresponding to the user''s
    input and sorted from most to less probable (the N-best list discussed earlier
    in this chapter).'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`EXTRA_MAX_RESULTS`：这个整数值指定了返回结果的最大数量限制。如果省略，识别器将决定返回多少结果。这些结果是用户输入的不同可能的文本，并从最可能到最不可能排序（本章前面讨论的最佳N列表）。'
- en: '`EXTRA_LANGUAGE`: This specifies a language that can be used instead of the
    default provided on the device. The use of other languages is covered in [Chapter
    7](ch07.html "Chapter 7. Multilingual and Multimodal Dialogs"), *Multilingual
    and Multimodal Dialogs*.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`EXTRA_LANGUAGE`：这指定了可以代替设备上提供的默认语言的语言。其他语言的使用在[第7章](ch07.html "第7章. 多语言和多模态对话")，*多语言和多模态对话*中进行介绍。'
- en: The user can be asked to choose from these options or they can be set programmatically.
    The `ASRWithIntent` app prompts the user for the language model and the maximum
    number of results. If the information is not provided, it uses the default values
    indicated in two constants (see the `showDefaultValues` and `setRecognitionParams`
    methods in the `asrwithintent.java` file).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 可以让用户从这些选项中选择，或者可以程序化地设置。`ASRWithIntent`应用会提示用户选择语言模型和最大结果数。如果没有提供这些信息，它会使用在两个常量中指示的默认值（请参阅`asrwithintent.java`文件中的`showDefaultValues`和`setRecognitionParams`方法）。
- en: 'The results of the speech recognition are returned via activity results in
    `onActivityResults(int, int, Intent)`. At this point, the recognition is complete.
    However, normally we would want to see the results or use them in some way. The
    additional steps required for this are illustrated in the following annotated
    code from `ASRWithIntent`:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 语音识别的结果会通过`onActivityResults(int, int, Intent)`中的活动结果返回。此时，识别已经完成。然而，通常我们会希望查看结果或以某种方式使用它们。为此需要执行的额外步骤在以下来自`ASRWithIntent`的注释代码中说明：
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As discussed earlier, the recognition results are returned through the intent.
    The matched sentences are accessible using the method `getStringArrayListExtra`
    using `RecognizerIntent.EXTRA_RESULTS` as a parameter. Similarly, an array with
    the confidence scores can be obtained with `getFloatArrayExtra` and `RecognizerIntent.EXTRA_CONFIDENCE_SCORES`.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如先前所讨论的，识别结果通过意图返回。可以使用`getStringArrayListExtra`方法，并传入`RecognizerIntent.EXTRA_RESULTS`作为参数来访问匹配的句子。同样，可以使用`getFloatArrayExtra`和`RecognizerIntent.EXTRA_CONFIDENCE_SCORES`获取带有置信度分数的数组。
- en: The results are held in a new `ArrayList<String>`, the elements of which combine
    the strings from the matches and scores (represented as strings) from the float
    array. Note that there is a possibility that the confidence score is -1; this
    is the case when the confidence score is unavailable. Then, `ArrayAdapter` is
    called in the `setListView` method to insert the formatted strings into the `ListView`
    method of the GUI.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 结果保存在一个新的`ArrayList<String>`中，其元素结合了匹配的字符串和浮点数组中的分数（表示为字符串）。请注意，有可能置信度分数是-1；这是置信度不可用时的情况。然后，在`setListView`方法中调用`ArrayAdapter`，将格式化的字符串插入到GUI的`ListView`中。
- en: 'It might also happen that the recognition could not be carried out satisfactorily
    (`resultCode!=RESULT_OK` in the previous code). There are different constants
    for the main error situations defined in the `RecognizerIntent` class: `RESULT_AUDIO_ERROR`,
    `RESULT_CLIENT_ERROR`, `RESULT_NETWORK_ERROR`, `RESULT_SERVER_ERROR`, and `RESULT_NOMATCH`.
    They all correspond to errors due to the physical device or the network, except
    for the last one that corresponds to the situation in which no phrase matched
    the audio input. Developers can use the result code to carry out a detailed treatment
    of these errors. However, the dialog shown already implements a naive treatment
    of such errors which may suffice for simpler apps. In this case, the user receives
    feedback on the errors and when it is applicable, they are asked to repeat their
    utterance.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 也可能发生识别无法满意进行的情况（在之前的代码中`resultCode!=RESULT_OK`）。在`RecognizerIntent`类中为主要的错误情况定义了不同的常量：`RESULT_AUDIO_ERROR`、`RESULT_CLIENT_ERROR`、`RESULT_NETWORK_ERROR`、`RESULT_SERVER_ERROR`和`RESULT_NOMATCH`。它们都对应于物理设备或网络的错误，最后一个对应于没有短语与音频输入匹配的情况。开发者可以使用结果代码对这些错误进行详细处理。然而，显示的对话框已经实现了一个简单的错误处理，对于较简单的应用来说可能已经足够。在这种情况下，用户会收到关于错误的反馈，并且在适用的情况下，他们会要求用户重复其话语。
- en: 'Finally, since the app needs to access the Internet to carry out speech recognition,
    it is necessary to set the permission in the `manifest` file:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，由于应用需要访问互联网以执行语音识别，因此需要在`manifest`文件中设置权限：
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ASRWithLib app
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ASRWithLib应用
- en: The `ASRWithLib` app has exactly the same functionality as `ASRWithIntent`,
    but instead of solely using a `RecognizerIntent` class, it creates an instance
    of the `SpeechRecognizer` class. In order to make the code usable in all the apps
    that employ ASR, we propose to use a library as we did in the previous chapter
    for TTS. In this case, the library is in `sandra.libs.asr.asrlib` and contains
    only one class `ASR`, which implements the `RecognitionListener` interface, and
    thus all the methods that cope with the different recognition events namely `onResults`,
    `onError`, `onBeginningOfSpeech`, `onBufferReceived`, `onEndOfSpeech`, `onEvent`,
    `onPartialResults`, `onReadyForSpeech`, and `onRmsChanged`.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`ASRWithLib`应用与`ASRWithIntent`具有完全相同的功能，但不是只使用`RecognizerIntent`类，而是创建`SpeechRecognizer`类的实例。为了使代码在所有使用ASR的应用程序中可用，我们建议使用库，就像上一章中为TTS所做的那样。在这种情况下，库位于`sandra.libs.asr.asrlib`中，只包含一个类`ASR`，它实现了`RecognitionListener`接口，因此所有处理不同识别事件的方法，即`onResults`、`onError`、`onBeginningOfSpeech`、`onBufferReceived`、`onEndOfSpeech`、`onEvent`、`onPartialResults`、`onReadyForSpeech`和`onRmsChanged`。'
- en: 'The `SpeechRecognizer` instance is created in the `createRecognizer` method
    after checking that the ASR engine is available in the device:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '`SpeechRecognizer`实例是在`createRecognizer`方法中创建的，在检查设备中是否可用ASR引擎之后：'
- en: '[PRE4]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This code queries the `PackageManager` class to check whether recognition is
    supported. If the value of `intActivities`.size() is greater than zero, speech
    recognition is supported, and an instance of `SpeechRecognizer` is then created
    and saved in the attribute `myASR`. The listener for recognition is set using
    a reference to `this`, as the ASR class implements the `RecognitionListener` interface.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码查询`PackageManager`类以检查是否支持识别。如果`intActivities`.size()的值大于零，则支持语音识别，然后创建`SpeechRecognizer`的实例并将其保存在属性`myASR`中。识别的监听器通过引用`this`来设置，因为ASR类实现了`RecognitionListener`接口。
- en: The `listen` method is used to start listening using a `RecognizerIntent` class.
    Although the extras are the same as in the `ASRWithIntent` app, the way in which
    the recognition is started is slightly different. `ASRWithIntent` used `startActivityForResult`
    while in this case, the `SpeechRecognizer` object is in charge of starting the
    recognition receiving the intent as an argument.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '`listen`方法用于通过`RecognizerIntent`类开始监听。尽管额外的内容与`ASRWithIntent`应用中的相同，但启动识别的方式略有不同。`ASRWithIntent`使用了`startActivityForResult`，而在这个案例中，`SpeechRecognizer`对象负责通过接收意图作为参数来启动识别。'
- en: '[PRE5]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In the `ASRWithIntent` app, all the code was in the same class and the testing
    for the correctness of the recognition parameters (`languageModel` and `maxResults`)
    was carried out in that single class. However, here we are building a library
    that will be used in many apps, thus it is not possible to take for granted that
    the parameters will be checked before invoking the `listen` method. This is why
    the method checks their values and throws an exception if they are not correct.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在`ASRWithIntent`应用中，所有代码都在同一个类中，识别参数（`languageModel`和`maxResults`）的正确性测试也在那个单独的类中进行。然而，这里我们正在构建一个将在许多应用中使用的库，因此不能想当然地认为在调用`listen`方法之前会检查参数。这就是为什么该方法会检查它们的值，如果它们不正确，则会抛出异常。
- en: Several methods are used to react to the different events that can be raised
    by the ASR engine. It is not a good policy to implement the response to such events
    in the library, firstly because it would imply that all apps that use the library
    make the same management of these events; secondly because most of the time responding
    to the events involves showing messages to the user or using the GUI in some other
    way, and it is a basic design principle to separate the logic of the application
    from its interface.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法用来响应ASR引擎可能引发的不同事件。在库中实现这些事件的响应并不是一个好的策略，首先，这意味着所有使用该库的应用程序都必须对事件进行相同的处理；其次，因为大多数时候，对事件的响应涉及到向用户显示消息或以其他方式使用图形用户界面，而将应用程序的逻辑与其界面分离是一个基本的设计原则。
- en: That is why the `ASR` class employs abstract methods. Abstract methods only
    declare the header, and it is the responsibility of the subclasses to provide
    the code for them. This way, each of the methods in charge of responding to ASR
    events invokes an abstract method, and the behavior of such methods varies for
    each of the subclasses of ASR. In the `ASRWithLib` example, the `ASRWithLib` class
    is a subclass of ASR and implements the abstract methods in a certain way. If
    we had another app in which we wanted to develop a different behavior, we could
    write separate code for those methods.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么`ASR`类使用抽象方法的原因。抽象方法只声明头部，具体子类负责为它们提供代码。这样，负责响应ASR事件的每个方法都调用一个抽象方法，而ASR的每个子类中这些方法的行为都不同。在`ASRWithLib`示例中，`ASRWithLib`类是ASR的一个子类，并以特定方式实现抽象方法。如果我们有另一个应用程序，想要开发不同的行为，可以为这些方法编写单独的代码。
- en: 'For example, the `onResults` method from the `ASR.java` class is invoked when
    the engine finds sentences that match what the user said. The code for this method
    in `ASR.java` is as follows. Note that to retrieve the results, it uses static
    methods from the `SpeechRecognizer` class, and not from `RecognizerIntent` as
    in `ASRWithIntent`:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当引擎找到与用户所说内容相匹配的句子时，会调用`ASR.java`类中的`onResults`方法。`ASR.java`中此方法的代码如下所示。请注意，为了获取结果，它使用了`SpeechRecognizer`类的静态方法，而不是像`ASRWithIntent`中那样使用`RecognizerIntent`：
- en: '[PRE6]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This method invokes the abstract method `processAsrResults`. It is in the `ASRWithLib`
    class where this method is implemented, indicating how to process the results
    (in this case by populating a list view as in `ASRWithIntent`).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法调用了抽象方法`processAsrResults`。在`ASRWithLib`类中实现了此方法，指出了如何处理结果（在这种情况下，是通过填充列表视图，如同`ASRWithIntent`中那样）。
- en: 'As you might have observed, the `ASRWithLib` app does not show the recognition
    dialog. This may be desirable in apps that perform continuous speech recognition
    (ASR is always active as a background service), for which such feedback can be
    annoying for the user. However, for other apps it is necessary to show some feedback
    to the user so that they know that the app is listening. This is carried out with
    the `onAsrReadyForSpeech` method. This method is executed when the ASR engine
    is ready to start listening, and is an abstract method from `ASRLib` implemented
    in `ASRWithLib.java` by changing the color and message of the speech button (both
    the text and color are not hard-coded but are retrieved from the `res/values`
    folder):'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如您可能已经观察到的，`ASRWithLib`应用程序没有显示识别对话框。这对于执行连续语音识别的应用程序（ASR始终作为后台服务活动）可能是可取的，因为此类反馈可能会使用户感到烦恼。然而，对于其他应用程序，需要向用户显示一些反馈，以便他们知道应用程序正在听。这是通过`onAsrReadyForSpeech`方法完成的。当ASR引擎准备好开始听时，执行此方法，这是来自`ASRLib`的抽象方法，在`ASRWithLib.java`中通过更改语音按钮的颜色和信息来实现（文本和颜色都不是硬编码的，而是从`res/values`文件夹中获取的）：
- en: '[PRE7]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Finally, it is necessary to set the permissions in the `manifest` file to access
    the Internet for using ASR and to record audio:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，需要在`manifest`文件中设置权限，以便使用ASR访问互联网和录制音频：
- en: '[PRE8]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Summary
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概括
- en: This chapter has shown how to use the Google speech API to implement speech
    recognition services, having checked that they are available on the device. The
    user is prompted to say some words and the results of the recognition, the recognized
    strings and their confidence scores, are displayed on the screen. The user can
    choose the language model for recognition and the maximum number of results to
    be retrieved. This functionality has been implemented following two different
    approaches in the `ASRWithIntent` and `ASRWithLib` apps.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 本章展示了如何使用谷歌语音API来实现语音识别服务，前提是检查设备上是否提供该服务。系统会提示用户说出一些词语，识别结果，即识别出的字符串及其置信度分数，将显示在屏幕上。用户可以选择识别的语言模型以及要检索的最大结果数。这一功能是通过`ASRWithIntent`和`ASRWithLib`应用程序中的两种不同方法来实现的。
- en: The `ASRWithIntent` app is a basic easy-to-develop example in which all the
    code is contained in the same class. ASR is carried out using a `RecognizerIntent`
    class and there is an automatically generated dialog that provides feedback on
    whether the engine is listening or if there was any error.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '`ASRWithIntent`应用程序是一个简单易开发的基本示例，所有代码都包含在同一个类中。ASR是通过使用`RecognizerIntent`类来完成的，并且有一个自动生成的对话框，提供反馈信息，指示引擎是否在听或是否出现错误。'
- en: The `ASRWithLib` app shows how to modularize and create a library for speech
    recognition that can be used in many apps. Instead of relying on the `RecognizerIntent`
    class only, it uses an instance of the `SpeechRecognizer` class and implements
    the `RecognitionListener` interface using abstract methods, providing a flexible
    implementation that can respond to a wide range of ASR events.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`ASRWithLib` 应用程序展示了如何模块化并创建一个语音识别库，该库可以在许多应用程序中使用。它不是仅依赖于 `RecognizerIntent`
    类，而是使用 `SpeechRecognizer` 类的实例，并使用抽象方法实现 `RecognitionListener` 接口，提供了一个灵活的实现，能够响应广泛的ASR事件。'
- en: While these two examples are not particularly useful apps as such, the code
    presented here can be used virtually unchanged in any apps using speech recognition.
    Future examples in this book will be built on this code. The next chapter will
    show how TTS and ASR can be combined to perform simple voice interactions in which
    the user can ask for information or issue a command to the device.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这两个示例并不是特别有用的应用程序，但这里展示的代码几乎可以原封不动地用在任何使用语音识别的应用程序中。本书后续的示例将基于此代码构建。下一章将展示如何结合TTS（文本到语音）和ASR（自动语音识别）来执行简单的语音交互，用户可以请求信息或向设备发出命令。
