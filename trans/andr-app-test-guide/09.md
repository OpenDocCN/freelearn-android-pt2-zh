# 第九章。性能测试和分析

在前几章中，我们研究并开发了针对我们的安卓应用程序的测试。这些测试让我们能够评估软件是否符合一定数量的规范，并通过对软件是否符合规范做出二进制判断，来确定软件的行为是否正确或符合这些规则。如果是，软件是正确的；如果没有，我们必须修复它，直到它。

在许多其他情况下，主要是在我们验证了软件符合所有这些规范之后，我们希望继续前进，了解它们是如何或以什么方式得到满足的，同时了解系统在不同情况下的表现，以分析可用性、速度、响应时间和可靠性等其他属性。

根据安卓开发者指南([http://developer.android.com/guide/index.html](http://developer.android.com/guide/index.html))，在设计我们的应用时，以下是最佳实践:

*   为性能而设计
*   响应性设计
*   为无缝设计

遵循这些最佳实践并从设计的一开始就主要从性能和响应性方面开始思考是极其重要的。由于我们的应用程序将在计算机能力有限的移动设备上运行，因此一旦我们的应用程序构建完毕(至少是部分构建完毕)，通过确定优化目标，并应用我们即将讨论的性能测试，可以获得更大的收益。

正如唐纳德·克努特多年前普及的那样:

> “过早*优化是万恶之源”*。

这些基于猜测、直觉甚至迷信的优化通常会在短期内干扰设计，并在长期内干扰可读性和可维护性。相反，*微优化*基于识别需要优化的瓶颈或热点，应用变化，然后再次进行基准测试，评估优化的改进。因此，我们在这里关注的重点是衡量现有的性能和优化方案。

本章将介绍与基准和概况相关的一系列概念，如下所示:

*   传统的日志语句方法
*   创建安卓性能测试
*   使用分析工具
*   使用卡尺的微基准

# 叶老洛格法

有时这对于真实场景来说太简单了，但我不会说在某些情况下它没有帮助，主要是因为它的实现需要几分钟，并且您只需要 `logcat`文本输出来分析案例，这在前面几章中描述的您想要自动化过程或应用持续集成的情况下会派上用场。

这种方法包括对一个方法或它的一部分进行计时，用两个时间度量来包围它，并在最后记录差异:

```java
/* (non-Javadoc)
* @see android.text.TextWatcher#onTextChanged( * java.lang.CharSequence, int, int, int)
*/
public void onTextChanged(CharSequence s, int start, int before, int count) {
if (!mDest.hasWindowFocus() || mDest.hasFocus() || s == null ) {
return;
}
final String str = s.toString();
if ( "".equals(str) ) {
mDest.setText("");
return;
} final long t0;
if ( BENCHMARK_TEMPERATURE_CONVERSION ) {
t0 = System.currentTimeMillis();
}
try {
final double temp = Double.parseDouble(str);
final double result = (mOp == OP.C2F) ? TemperatureConverter.celsiusToFahrenheit(temp) : TemperatureConverter.fahrenheitToCelsius(temp);
final String resultString = String.format("%.2f", result);
mDest.setNumber(result);
mDest.setSelection(resultString.length());
} catch (NumberFormatException e) {
// WARNING
// this is generated while a number is entered,
// for example just a '-'
// so we don't want to show the error
} catch (Exception e) {
mSource.setError("ERROR: " + e.getLocalizedMessage());
} if ( BENCHMARK_TEMPERATURE_CONVERSION ) {
long t = System.currentTimeMillis() - t0;
Log.i(TAG, "TemperatureConversion took " + t + " ms to complete.");
}
}

```

这很简单。我们计算时间，记录差异。为此，我们使用 `Log.i()`方法，在运行应用程序时，我们可以在 `logcat`中看到输出。您可以通过将 `true`或 `false`设置为您应该在其他地方定义的 `BENCHMARK_TEMPERATURE_CONVERSION`常数来控制该基准的执行。

当我们在 `logcat`中将 `BENCHMARK_TEMPERATURE_CONVERSION`常量设置为真来启动活动时，每次转换发生时，我们都会收到如下消息:

**信息/温度转换率(392):温度转换用了 55 毫秒完成**。

**信息/温度转换率(392):温度转换需要 11 毫秒完成**。

**信息/温度转换率(392):温度转换需要 5 毫秒完成**。

您应该考虑的是，这些支持基准测试的常量不应该在生产版本中启用，因为使用了其他常见的常量，如 DEBUG 或 LOGD。为了避免这个错误，您应该在用于自动化构建(如 Ant 或 Make)的构建过程中集成这些常量值的验证。

很简单，但这不适用于更复杂的情况。

# 安卓 SDK 中的性能测试

如果前面添加日志语句的方法不适合您，那么有一种不同的方法可以从我们的应用程序中获得性能测试结果。

不幸的是，安卓 SDK 中的性能测试是半生不熟的(至少到本书撰写时可用的最新版本安卓 2.3 姜饼)。从安卓软件开发工具包应用程序中获取性能测试结果没有合理的方法，因为安卓测试使用的类隐藏在安卓软件开发工具包中，仅适用于系统应用程序，即作为主构建或系统映像的一部分构建的应用程序。该策略不适用于 SDK 应用程序，因此我们不会在该方向上深入挖掘，我们将专注于其他可用的选择。

## 启动性能测试

这些测试基于类似的方法，就像安卓用来测试系统应用程序的方法。这个想法是扩展 `android.app.Instrumentation`来提供性能快照，自动创建一个我们甚至可以扩展来满足其他需求的框架。由于这种媒介的限制，我们在这里提出一个简单的例子。

### 创建启动性能基础工具

我们的第一步是扩展 `Instrumentation`来提供我们需要的功能。我们正在使用一个名为 `com.example.aatg.tc.test.launchperf`的新包来保持我们的测试有条不紊:

```java
package com.example.aatg.tc.test.launchperf;
import android.app.Instrumentation;
import android.content.Intent;
import android.os.Bundle;
import android.util.Log;
/**
* Base class for all launch performance Instrumentation classes.
*/
public class LaunchPerformanceBase extends Instrumentation {
public static final String TAG = "LaunchPerformanceBase";
protected Bundle mResults;
protected Intent mIntent;
/**
* Constructor.
*/
public LaunchPerformanceBase() {
mResults = new Bundle();
mIntent = new Intent(Intent.ACTION_MAIN);
mIntent.setFlags(Intent.FLAG_ACTIVITY_NEW_TASK);
setAutomaticPerformanceSnapshots();
}
/**
* Launches intent {@link #mIntent}, and waits for idle before
* returning.
*/
protected void LaunchApp() {
startActivitySync(mIntent);
waitForIdleSync();
}
@Override
public void finish(int resultCode, Bundle results) {
Log.v(TAG, "Test reults = " + results);
super.finish(resultCode, results);
}
}

```

我们在这里扩展 `Instrumentation`。构造函数初始化了这个类中的两个字段: `mResults`和 `mIntent`。最后，我们调用方法 `setAutomaticPerformanceSnapshots()`，这是创建这个性能测试的关键。

方法 `LaunchApp()`负责启动想要的 `Activity`，等待后返回。

`finish()`方法记录收到的结果，然后调用 `Instrumentation's finish()`。

### 创建温度转换实践运行性能类

这个类设置 `Intent`来调用 `TemperatureConverterActivity`并提供 `LaunchPerformanceBase`类提供的基础设施来测试启动我们的 `Activity:` 的性能

```java
package com.example.aatg.tc.test.launchperf;
import com.example.aatg.tc.TemperatureConverterActivity;
import android.app.Activity;
import android.os.Bundle;
/**
* Instrumentation class for {@link TemperatureConverterActivity} launch performance testing.
*/
public class TemperatureConverterActivityLaunchPerformance extends LaunchPerformanceBase {
/**
* Constructor.
*/
public TemperatureConverterActivityLaunchPerformance() {
super();
}
@Override
public void onCreate(Bundle arguments) {
super.onCreate(arguments);
mIntent.setClassName("com.example.aatg.tc", "com.example.aatg.tc.TemperatureConverterActivity");
start();
}
/**
* Calls LaunchApp and finish.
*/
@Override
public void onStart() {
super.onStart();
LaunchApp();
finish(Activity.RESULT_OK, mResults);
}
}

```

这里， `onCreate()`按照安卓生命周期的要求调用 `super.onCreate()`。然后设置 `Intent`，指定类名和包。然后其中一个 `Instrumentation's`方法被调用， `start()`，它创建并启动一个新的线程来运行检测。这个新线程将调用 `onStart()`，在这里您可以实现仪器。

然后 `onStart()`执行，调用 `LaunchApp()`和 `finish()`。

## 运行测试

为了能够运行这个测试，我们需要在 `TemperatureConverterTest`项目的 `AndroidManifest.xml`中定义具体的 `Instrumentation`。

这是我们必须添加到清单中的代码片段:

```java
<?xml version="1.0" encoding="utf-8"?>
<manifest xmlns:android="http://schemas.android.com/apk/res/android" package="com.example.aatg.tc.test" android:versionCode="1" android:versionName="1.0">
<application android:icon="@drawable/icon" android:label="@string/app_name">
<uses-library android:name="android.test.runner" />
</application>
<uses-sdk android:minSdkVersion="9" />
<instrumentation android:targetPackage="com.example.aatg.tc" android:name="android.test.InstrumentationTestRunner" android:label="Temperature Converter Activity Tests" android:icon="@drawable/icon" /> <instrumentation android:targetPackage="com.example.aatg.tc" android:label="Temperature Converter Activity Launch Performance" android:name=".launchperf.TermeratureConverterActivity LaunchPerformance" />
</manifest>

```

一旦一切就绪，我们就可以开始运行测试了。

首先，安装包含这些更改的 APK。然后，我们有几个选项来运行测试，正如我们在前面几章中回顾的那样。在这种情况下，我们使用命令行，因为这是获取所有细节的最简单方法。更换适用于您的案例的序列号:

```java
$ adb -s emulator-5554 shell am instrument -w com.example.aatg.tc.test/.launchperf.TermeratureConverterActivityLaunchPerformance

```

我们在标准输出中收到该测试的一组结果:

```java
INSTRUMENTATION_RESULT: other_pss=13430
INSTRUMENTATION_RESULT: java_allocated=2565
INSTRUMENTATION_RESULT: global_freed_size=16424
INSTRUMENTATION_RESULT: native_private_dirty=504
INSTRUMENTATION_RESULT: native_free=6
INSTRUMENTATION_RESULT: global_alloc_count=810
INSTRUMENTATION_RESULT: other_private_dirty=12436
INSTRUMENTATION_RESULT: global_freed_count=328
INSTRUMENTATION_RESULT: sent_transactions=-1
INSTRUMENTATION_RESULT: java_free=2814
INSTRUMENTATION_RESULT: received_transactions=-1
INSTRUMENTATION_RESULT: pre_sent_transactions=-1
INSTRUMENTATION_RESULT: other_shared_dirty=5268
INSTRUMENTATION_RESULT: pre_received_transactions=-1 INSTRUMENTATION_RESULT: execution_time=4563
INSTRUMENTATION_RESULT: native_size=11020
INSTRUMENTATION_RESULT: native_shared_dirty=1296 INSTRUMENTATION_RESULT: cpu_time=1761
INSTRUMENTATION_RESULT: java_private_dirty=52
INSTRUMENTATION_RESULT: native_allocated=11013
INSTRUMENTATION_RESULT: gc_invocation_count=0
INSTRUMENTATION_RESULT: java_shared_dirty=1860
INSTRUMENTATION_RESULT: global_alloc_size=44862
INSTRUMENTATION_RESULT: java_pss=1203
INSTRUMENTATION_RESULT: java_size=5379
INSTRUMENTATION_RESULT: native_pss=660
INSTRUMENTATION_CODE: -1

```

我们强调了我们感兴趣的两个值:**执行时间**和 **cpu 时间**。它们分别说明总执行时间和使用的 CPU 时间。

在仿真器上运行该测试会增加错误测量的可能性，因为主机正在运行其他也占用 CPU 的进程，而仿真器不一定代表真实硬件的性能。

正因为如此，我们正在考虑这两项措施。 `execution_time`给出了实时时间， `cpu_time`给出了 CPU 计算代码所用的总时间。

不用说，在这种情况下以及任何其他测量随时间变化的事物的情况下，您应该使用测量策略并多次运行测试以获得不同的统计值，例如平均值或标准偏差。

不幸的是，安卓 ADT 的当前实现不允许使用不扩展 `android.test.InstrumentationTestRunner`的工具，尽管 `.launchperf.TemperatureConverterActivityLaunchPerformance`扩展了 `LaunchPerformaceBase`扩展了 `Instrumentation`。

此屏幕截图显示了试图在 Eclipse 运行配置中定义此工具时出现的错误:

![Running the tests](img/3500_09_01.jpg)

# 使用 Traceview 和 dmtracedump 平台工具

安卓软件开发工具包在其各种工具中包括两个专门用于分析性能问题并潜在地确定应用优化的目标的工具。

这些工具比其他替代工具有优势:对于更简单的任务，通常不需要修改源代码。然而，对于更复杂的情况，需要一些补充，但是它们非常简单，我们很快就会看到。

如果您不需要精确地开始和停止跟踪，您可以从命令行或 Eclipse 驱动它。例如，要从命令行开始跟踪，可以使用以下命令。记住替换适用于您的情况的序列号:

```java
$ adb -s emulator-5554 am start -n com.example.aatg.tc/.TemperatureConverterActivity
$ adb -s emulator-5554 shell am profile com.example.aatg.tc start /mnt/sdcard/tc.trace

```

做一些事情，例如在摄氏度字段中输入一个温度来强制转换。

```java
$ adb -s emulator-5554 shell am profile com.example.aatg.tc stop
$ adb -s emulator-5554 pull /mnt/sdcard/tc.trace /tmp/tc.trace
1132 KB/s (2851698 bytes in 2.459s)
$ traceview /tmp/tc.trace

```

否则，如果您需要更精确的分析开始时间，您可以添加这段代码来代替前面的代码:

```java
@Override
public void onTextChanged(CharSequence s, int start, int before, int count) {
if (!dest.hasWindowFocus() || dest.hasFocus() || s == null ) {
return;
}
final String ss = s.toString();
if ( "".equals(ss) ) {
dest.setText("");
return;
} if ( BENCHMARK_TEMPERATURE_CONVERSION ) {
Debug.startMethodTracing();
}
try {
final double result = (Double) convert.invoke( TemperatureConverter.class, Double.parseDouble(ss));
dest.setNumber(result);
dest.setSelection(dest.getText().toString().length());
} catch (NumberFormatException e) {
// WARNING
// this is generated while a number is entered,
//for example just a '-'
// so we don't want to show the error
} catch (Exception e) {
dest.setError(e.getCause().getLocalizedMessage());
} if ( BENCHMARK_TEMPERATURE_CONVERSION ) {
Debug.stopMethodTracing();
}
}

```

这将创建一个跟踪文件，通过调用 `Debug.startMethodTracing()`使用 sd 卡中的默认名称 `dmtrace.trace`，这将使用默认日志名称和缓冲区大小启动方法跟踪。完成后，我们打电话给 `Debug.stopMethodTracing()`停止侧写。

### 注

为了能够写入 sd 卡，应用程序需要在清单中添加 `android.permission.WRITE_EXTERNAL_STORAGE`权限。

对于早于安卓 2.2 的虚拟机，即使在 Eclipse 中这样做也需要权限，因为文件也是生成的。从安卓 2.2 开始，流通过 JDWP 连接发送，不再需要权限。

为了获得跟踪文件，您需要运行应用程序。该文件需要拉至开发计算机使用 `traceview:`进行进一步分析

```java
$ adb -s emulator-5554 pull /mnt/sdcard/dmtrace.trace /tmp/dmtrace.trace
375 KB/s (50664 bytes in 0.131s)
$ traceview /tmp/dmtrace.trace

```

运行该命令后，出现 `traceview's`窗口，显示所有收集的信息:

![Using the Traceview and dmtracedump platform tools](img/3500_09_02.jpg)

### 注

请记住，启用概要分析确实会降低应用程序的执行速度，因此应该通过相对权重而不是绝对值来解释度量。

窗口的顶部显示了**时间线面板**和每个方法的彩色区域。时间向右增加。彩色行下面还有小线条，显示对所选方法的所有调用的范围。

我们分析了应用程序的一小部分，因此只有主线程在运行。在分析期间其他线程正在运行的其他情况下，也会显示此信息。

底部显示**概要面板**和执行的每个方法及其父子关系。我们称调用方法为*父母*，称调用方法为*子女*。单击时，方法会展开以显示其父级和子级。父母是紫色背景，孩子是黄色背景。

此外，以循环方式为方法选择的颜色显示在方法名称之前。

最后，在底部有一个**查找:**字段，我们可以在其中输入一个过滤器来减少显示的信息量。例如，如果我们只对 `com.example.aatg.tc`包中的显示方法感兴趣，我们应该输入 **com/example/aatg/tc** 。

单击一列将根据该列的升序或降序设置列表的顺序。

此表描述了可用的列及其说明:

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

圆柱

 | 

描述

 |
| --- | --- |
| 名字 | 方法的名称，包括上述形式的包名，使用“/”(斜杠)作为分隔符。还会显示参数和返回类型。 |
| 包含百分比 | 方法使用的包含时间占总时间的百分比。这包括它的所有孩子。 |
| 包括的 | 此方法使用的包含时间，以毫秒为单位。包括这个方法及其所有子方法。 |
| 不包括% | 方法使用的独占时间占总时间的百分比。那就是排除了它所有的孩子。 |
| 独家的 | 独占时间，以毫秒为单位，这是此方法花费的总时间。那就是排除了它所有的孩子。 |
| 呼叫+重复通话/总计 | 此列显示此方法的调用次数和递归调用次数。与对此方法的调用总数相比的调用数。 |
| 时间/呼叫 | 每次呼叫的时间(毫秒)。这是包容性/通话。 |

# 微基准

基准测试是运行计算机程序或操作的行为，以便以产生定量结果的方式比较操作，通常是通过对它们运行一组测试和试验。

基准可以分为两大类:

*   宏观基准
*   微基准

**macro benchmark**的存在是作为一种手段，在处理器速度、单位时间浮点运算次数、图形和 3D 性能等特定领域对不同平台进行比较。它们通常用于硬件组件，但也可用于测试软件特定领域，如编译器优化或算法。

与这些传统的宏基准相反，一个**微基准**试图测量一小段代码的性能，通常是一个单一的方法。获得的结果用于在提供相同功能的竞争实现之间进行选择，从而决定优化路径。

这里的风险是微基准不同于你认为你正在测量的东西。这是安卓从 2.2 版本 Froyo 开始使用的 JIT 编译器需要考虑的。JIT 编译器编译和优化微基准的方式可能不同于应用程序中的相同代码。所以，做决定时要谨慎。

这与上一节中介绍的分析策略不同，因为这种方法不考虑整个应用程序，而是一次只考虑一个方法或算法。

## 卡尺微基准

**Caliper** 是谷歌的开源框架，用于编写、运行和查看微博客的结果。在[http://code.google.com/p/caliper/](http://code.google.com/p/caliper/)网站上有很多例子和教程。

这是一项正在进行的工作，但在许多情况下仍然有用。我们正在这里探索它的基本用途，并将在下一章中介绍更多与安卓相关的用途。

它的中心思想是基准方法，主要是了解它们的效率有多高；我们可能会决定这是我们优化的目标，也许是在分析了通过 traveview 分析提供的结果之后。

卡尺基准正常延伸 `com.google.caliper.SimpleBenchmark`，实现 `Benchmark`接口。基准测试的结构与 JUnit 3 测试相似，保持相同的结构，不同之处在于基准测试以前缀 **time** 开始，而不是 **test** 。然后，每个基准测试都接受一个通常被命名为 `reps`的 `int`参数，该参数指示对位于方法内部的代码进行基准测试的重复次数，该方法被一个计算重复次数的循环所包围。

`setUp()`方法也存在。

我们需要在电脑里安装卡尺。在写这篇文章的时候，caliper 并不是以二进制的形式发布的，而是作为你可以自己下载和构建的源代码发布的。遵循其网站上提供的说明，该网站基本上是获取源代码和建设自己。

简单地说，您可以使用这些命令行来完成。您需要安装 Subversion 和 Ant 来完成这项工作:

```java
$ svn checkout http://caliper.googlecode.com/svn/trunk/ caliper-read-only
$ cd caliper-read-only
$ ant

```

`calliper-0.0.jar`和 `allocation.jar`会在 `build/caliper-0.0/lib`子目录中找到。

### 创建温度转换基准项目

让我们从在 Eclipse 中创建新的 Java 项目开始。是的，这次不是安卓项目，只是 Java。

为了一致性，使用包装 `com.example.aatg.tc.benchmark`作为主包装。

将 `caliper`库和现有的 `TemperatureConverter`项目添加到项目属性中的 **Java 构建路径**中。

然后创建包含我们的基准的 `TemperatureConverterBenchmark`类:

```java
package com.example.aatg.tc.benchmark;
import java.util.Random;
import com.example.aatg.tc.TemperatureConverter;
import com.google.caliper.Param;
import com.google.caliper.SimpleBenchmark;
/**
* Caliper Benchmark.<br>
* To run the benchmarks in this class:<br>
* {@code $ CLASSPATH=... caliper com.example.aatg.tc. * benchmark.TemperatureConverterBenchmark. * CelsiusToFahrenheitBenchmark} [-Dsize=n]
*
* @author diego
*
*/
public class TemperatureConverterBenchmark {
public static class CelsiusToFahrenheitBenchmark extends SimpleBenchmark {
private static final double T = 10; // some temp
@Param
int size;
private double[] temps;
@Override
protected void setUp() throws Exception {
super.setUp();
temps = new double[size];
Random r = new Random(System.currentTimeMillis());
for (int i=0; i < size; i++) {
temps[i] = T * r.nextGaussian();
}
}
public final void timeCelsiusToFahrenheit(int reps) {
for (int i=0; i < reps; i++) {
for (double t: temps) {
TemperatureConverter.celsiusToFahrenheit(t);
}
}
}
}
public static void main(String[] args) {
System.out.println("This is a caliper benchmark.");
}
}

```

我们有一个 `setUp()`方法，类似于 JUnit 测试，在基准测试运行之前运行。此方法初始化转换基准中使用的随机温度数组。该数组的大小作为参数传递给测径器，并在这里用 `@Param`注释进行注释。卡尺将自动提供该参数的值。

我们对伪随机温度使用高斯分布，因为这可能是现实的一个很好的模型。

然后是基准本身。正如我们之前提到的，它应该以前缀 time 开始，如本例中的 `timeCelsiusToFahrenheit()`。在这个方法中，我们循环重复并调用转换 `TemperatureConverter.celsiusToFahrenheit()`，这是我们希望进行基准测试的方法。

### 行车卡钳

为了运行卡尺，我们使用一个基于发行版附带的脚本的脚本。请务必将其放在包含在 `PATH`中的目录中，或者使用正确的路径来调用它:

```java
#!/bin/bash
VERSION=0.0
CALIPER_DIR=/opt/caliper-$VERSION
export PATH=$PATH:$JAVA_HOME/bin
exec java -cp ${CALIPER_DIR}/lib/caliper-${VERSION}.jar:$CLASSPATH com.google.caliper.Runner "$@"

```

让它适应你的需求。在运行它之前，请记住，我们仍然需要设置我们的 `CLASSPATH`，这样卡钳就可以找到 `TemperatureConverter`和基准本身。例如:

```java
$ export CLASSPATH=$CLASSPATH:~/workspace/TemperatureConverter/bin:~/workspace/TemperatureConverterBenchmark/bin

```

之后，我们可以按如下方式运行测径仪:

```java
$ caliper com.example.aatg.tc.benchmark.TemperatureConverterBenchmark.CelsiusToFahrenheitBenchmark -Dsize=1

```

这将运行基准测试，如果一切顺利，我们将看到结果:

**0%场景{vm=java，benchmark =celsiusto 华氏，size = 1 } 8.95nsσ=0.11ns @ 10 次试验**

**。发现卡利佩雷克，正在读取属性..**。

**ns 对数运行时间**

**9 xxxxxxxxxxxxxxxxxxxxxxxxxxx**

**虚拟机:java**

**基准:摄氏度华氏**

**尺寸:1**

或者，我们可以针对不同的温度重复基准测试，以了解这些值本身是否会影响转换性能。在这种情况下，我们运行:

```java
$ caliper com.example.aatg.tc.benchmark.TemperatureConverterBenchmark.CelsiusToFahrenheitBenchmark -Dsize=1,10,100

```

这里，我们为温度阵列添加了不同的大小，获得的结果如下:

**0% Scenario{vm=java，trial=0，benchmark =celsiusto 华氏，size = 1 } 3.47 nsσ=0.19 ns @ 10 次试验**

**33%场景{vm=java，试用=0，基准=celsiusto 华氏度，大小= 10 } 11.67 nsσ=1.20 ns @ 10 次试验**

**67%场景{vm=java，trial=0，benchmark =celsiusto 华氏，size = 100 } 63.06 nsσ=3.83 ns @ 10 次试验**

**67%场景{vm=java，trial=0，benchmark =celsiusto 华氏，size = 100 } 63.06 nsσ=3.83 ns @ 10 次试验**

**尺寸 ns 线性运行时间**

**1 3.47 =**

**10 11.67 =====**

**100 63.06 = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =**

**虚拟机:java**

**试验:0**

**基准:摄氏度华氏**

为了帮助可视化这些结果，谷歌 app engine([http://microbenchmarks.appspot.com](http://microbenchmarks.appspot.com))中托管了一项服务，该服务接受您的结果数据，并让您以更好的方式可视化它们。要访问这项服务，您应该获得一个提供您的谷歌登录的应用编程接口密钥。一旦获得此密钥，它将被放入您主目录中的 `.caliperrc`文件中，下次您运行基准测试时，结果将被上传。

在您粘贴了获得的应用编程接口密钥后， `.caliperrc`看起来像这个片段:

```java
# Caliper API key for myuser@gmail.com
postUrl: http://microbenchmarks.appspot.com:80/run/
apiKey: 012345678901234567890123456789012

```

现在使用与之前相同的命令行再次运行基准测试:

```java
$ caliper com.example.aatg.tc.benchmark.TemperatureConverterBenchmark.CelsiusToFahrenheitBenchmark -Dsize=1,10,100

```

除了文本输出，您还将收到在线访问结果的说明。您可以在线查看当前和以前的基准测试结果，网址为:

[http://microbenchmarks . app spot . com/run/user @ Gmail . com/com . example . aatg . TC . benchmark . temperatecoverterbenchmark . celsiustofahrenheitbenchmark](http://microbenchmarks.appspot.com/run/user@gmail.com/com.example.aatg.tc.benchmark.TemperatureConverterBenchmark.CelsiusToFahrenheitBenchmark)。

### 注

在前面的网址中，用您用来生成应用编程接口密钥的真实谷歌登录用户名替换 `user@gmail.com`。

![Running caliper](img/3500_09_03.jpg)

# 总结

在本章中，我们剖析了测试应用程序基准测试和代码分析的性能度量的可用替代方法。

虽然在撰写本文时，安卓 SDK 应该提供的一些选项尚未完成，并且由于一些代码隐藏在 SDK 中，因此没有可能实现安卓 `PerformanceTestCases`，但我们访问并分析了一些其他有效的替代方案。

在这些备选方案中，我们发现可以使用简单的日志语句来更复杂地扩展 Instrumentation 代码。

随后，我们分析了分析备选方案，并描述和举例说明了 `traceview`和 `dmtracedump`的使用。

最后，我们发现了卡尺——一个对安卓有本地支持的微基准测试工具。然而，我们介绍了它最基本的用法，并将更具体的安卓和达尔维克虚拟机用法推迟到下一章。

在下一章中，我们将从源代码构建安卓系统，以获得一个 EMMA 仪表化的构建，我们将对我们的代码执行覆盖率报告。在这一章的最后，我们还将介绍替代的战术和工具。